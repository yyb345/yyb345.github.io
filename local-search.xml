<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>01-AI技术-大模型工程技术汇总</title>
    <link href="/2024/04/04/01-%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%B7%A5%E7%A8%8B%E6%8A%80%E6%9C%AF%E6%B1%87%E6%80%BB/"/>
    <url>/2024/04/04/01-%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%B7%A5%E7%A8%8B%E6%8A%80%E6%9C%AF%E6%B1%87%E6%80%BB/</url>
    
    <content type="html"><![CDATA[<p>本文记录一下最近一个月学习的大模型相关的技术知识点，为拥抱AI浪潮做些技术储备。</p><h2 id="大模型术语相关"><a href="#大模型术语相关" class="headerlink" title="大模型术语相关"></a><strong>大模型术语相关</strong></h2><h3 id="参数规模"><a href="#参数规模" class="headerlink" title="参数规模"></a><strong>参数规模</strong></h3><p>GPT 3.5 千亿级别</p><p>GPT4 1.8W亿级别</p><p>国内一般都是十亿或百亿级别</p><p>ChatGLM2_2K_6B </p><p>BAICHUAN_4K_13B</p><p>淘宝星辰_4K_13B</p><h3 id="TOKEN长度"><a href="#TOKEN长度" class="headerlink" title="TOKEN长度"></a><strong>TOKEN长度</strong></h3><p>Token是指被LLM处理的离散的数据单元，可能是一个单词、也可能是一个字符，这个是由上下文决定的。</p><p>TOKEN数量是指 输入和输出加起来的长度之和</p><p>TOKEN数量，决定了 prompt和输出的长度，同样会影响推理的速度，prompt越长，推理时间越长。</p><p><strong>TOKEN的数量为什么会有上限，是有什么限制么？</strong></p><h3 id="各个版本的token数量限制"><a href="#各个版本的token数量限制" class="headerlink" title="各个版本的token数量限制"></a><strong>各个版本的token数量限制</strong></h3><p>GPT3.5-turbo 是4096个token</p><p>GPT3.5_16K</p><p>GPT4_Turbo_128K</p><p><strong>大模型工程落地相关</strong></p><h3 id="prompt"><a href="#prompt" class="headerlink" title="prompt"></a><strong>prompt</strong></h3><p>零样本</p><p>少样本：通过举例</p><p>思维链</p><p>角色、限制条件</p><h3 id="LangChain"><a href="#LangChain" class="headerlink" title="LangChain"></a><strong>LangChain</strong></h3><p>软件开发框架，帮助开发者快速且灵活地调用大模型，也封装了许多常见的chain，可以被业务快速使用。</p><h3 id="Semantic-Kernel"><a href="#Semantic-Kernel" class="headerlink" title="Semantic-Kernel"></a><strong>Semantic-Kernel</strong></h3><p>微软的一个工程框架，也可以实现langchain的基本功能，不过更适用于多agent的框架。</p><h3 id="RAG（检索增强生成）"><a href="#RAG（检索增强生成）" class="headerlink" title="RAG（检索增强生成）"></a><strong>RAG（检索增强生成）</strong></h3><p>是一种结合外部知识库来增强LLM生成能力的总称。</p><h3 id="向量数据库"><a href="#向量数据库" class="headerlink" title="向量数据库"></a><strong>向量数据库</strong></h3><p>Embedding：将现实世界中的物质向量化到高维空间，向量距离通常代表了自然语言的语义相似度。</p><p>召回：向量召回、搜索召回</p><h3 id="Agent"><a href="#Agent" class="headerlink" title="Agent"></a><strong>Agent</strong></h3><p>简单来说是具有某个功能的原子能力，可以被大模型调用到。</p><h3 id="多Agent"><a href="#多Agent" class="headerlink" title="多Agent"></a><strong>多Agent</strong></h3><p>多个agent协同完成一个目标，比如metaGPT</p><p><strong>大模型训练相关</strong></p><h3 id="预训练"><a href="#预训练" class="headerlink" title="预训练"></a><strong>预训练</strong></h3><p>通过大量的数据训练出来的模型</p><h3 id="推理"><a href="#推理" class="headerlink" title="推理"></a><strong>推理</strong></h3><p>模型根据已有的经验，对用户的输入进行预测。</p><h3 id="微调"><a href="#微调" class="headerlink" title="微调"></a><strong>微调</strong></h3><p>预训练好的模型在特定的任务上进行微调，使用有标签的小规模数据集</p><h3 id="训练基础设施"><a href="#训练基础设施" class="headerlink" title="训练基础设施"></a><strong>训练基础设施</strong></h3><p>pytorch 是一种深度学习框架，用来训练大模型的，transformer是一种模型机制。</p><h3 id="计算资源"><a href="#计算资源" class="headerlink" title="计算资源"></a><strong>计算资源</strong></h3><p>CPU：传统的CPU芯片，重逻辑，轻计算。</p><p>GPU：类众核CPU，重计算，轻逻辑。A100 H100 4096等，代表了不同的算力，常见的衡量指标有Flops</p><p>TPU ：谷歌出的类似于GPU的芯片</p><h2 id="LangChain框架"><a href="#LangChain框架" class="headerlink" title="LangChain框架"></a><strong>LangChain框架</strong></h2><h3 id="1-LangChain解决什么问题"><a href="#1-LangChain解决什么问题" class="headerlink" title="1. LangChain解决什么问题"></a><strong>1. LangChain解决什么问题</strong></h3><p>LangChain是基于LLM之上的，在应用层和底层LLM之前的一个很好的编程框架，如果把LLM比喻为各种类型的数据库、中间件等这些基础设施，应用层是各种业务逻辑的组合之外，那么LangChain就负责桥接与业务层和底层LLM模型，让开发者可以快速地实现对接各种底层模型和快速实现业务逻辑的软件开发框架。</p><p>那么LangChain是如何做到的呢？试想一下，现在底层有一个大模型的推理能力，除了在对话框手动输入跟他聊天之外。如何用计算机方式跟它互动呢？如果把一次LLM调用当作一个原子能力，如何编排这些原子能力来解决一些业务需求呢？Langchain就是来解决这个事情的。</p><h3 id="2-LangChain的几个核心概念"><a href="#2-LangChain的几个核心概念" class="headerlink" title="2. LangChain的几个核心概念"></a><strong>2. LangChain的几个核心概念</strong></h3><h4 id="格式化数据（I-x2F-O）"><a href="#格式化数据（I-x2F-O）" class="headerlink" title="格式化数据（I&#x2F;O）"></a><strong>格式化数据（I&#x2F;O）</strong></h4><h4 id="Retriver"><a href="#Retriver" class="headerlink" title="Retriver"></a><strong>Retriver</strong></h4><p>检索是为了解决大模型打通用户的本身数据，做一些面向业务属性的东西。这里的检索并非传统的关系型数据库，更多的是与大模型的本身逻辑相似的，比如向量数据库。</p><p><strong>一个经典的结合LLM和外部用户的文档进行智能答疑的场景</strong></p><p>文档-&gt;分词-&gt;embedding-&gt;向量数据库</p><p>query-&gt;向量数据库查询-&gt;TOP N-&gt;上下文+ 用户提问 + prompt -&gt; LLM -&gt; 返回结果</p><p>一个经典的图如下：</p><p><img src="https://pic1.zhimg.com/80/v2-d05ae1eea26c6ce55b3a98cf7a8870cc_1440w.jpg?source=d16d100b" alt="img"></p><p>添加图片注释，不超过 140 字（可选）</p><p><strong>关键技术：文档如何拆分、embedding过程、 TOPN 向量距离的选择</strong></p><p>embedding技术选型</p><p>embedding是将现实中的物体通过向量化的方法转化为高维向量，可被机器学习模型所识别。他是一种映射，同时也保证了能清晰地表达现实物体的特征。基于此，可以进行一些归类分析、回归分析等。</p><p>现在市面上常见的embedding方法有通义千问的embedding等方法。</p><p>向量数据库</p><p>向量数据库底层存储的是一堆向量，它提供了根据向量相似度进行查询的能力，一般情况下，向量相似度代表了现实世界中物体的相似度。比如”我的名字是小明“ 和“我叫小明”这两句话所代表的含义几乎是相同的，那么在embedding之后，基于向量数据库进行查询的时候，它们俩的相似度就会很近。</p><h4 id="Chain"><a href="#Chain" class="headerlink" title="Chain"></a><strong>Chain</strong></h4><p>各种类型的chain，chain代表了各种业务类型的组合，类似于工作流的编排。</p><h4 id="Memory"><a href="#Memory" class="headerlink" title="Memory"></a><strong>Memory</strong></h4><p>LLM本身提供了记忆的能力，同时提供了接口，开发者可以将历史的对话记录传入给LLM。LangChain需要使用外部存储保存这些历史的会话和记忆。可以使用数据库、缓存等进行保存。</p><h4 id="Agent-1"><a href="#Agent-1" class="headerlink" title="Agent"></a><strong>Agent</strong></h4><p><strong>重点是代理工具</strong></p><p>代理工具可以让应用程序基于大模型的推理能力，然后进行代理工具或代理服务的调用。因为LLM是没有“联网”的能力的，如果想解决特定的应用场景，代理工具是个完美的选择。</p><p>代理工具通常包含三个方面： 用户输入、prompt编排LLM思考与路由代理的过程、背后的代理服务。其中难点可能就在于prompt设计了。通常的“套路”是这样的：</p><p><strong>ReAct 模型</strong></p><p>输入：用户的问题</p><p>思考过程：如果是情况1（这个是需要LLM进行意图识别进行思考的），那么推理和提取出一些关键参数，调用agent1，如果是情况2，那么推理和提取出一些关键参数，调用agent2</p><p>Act：调用agent1对应一个JSON格式化的输入，调用function1，返回结果。</p><p>观察：观察调用后的结果，再结合推理的能力，再进行循环思考。</p><h2 id="Semantic-Kernel-框架"><a href="#Semantic-Kernel-框架" class="headerlink" title="Semantic Kernel 框架"></a>Semantic Kernel 框架</h2><p>功能基本与langchain功能相同，在应用层和LLM层中间实现了一个编程框架。框架可以灵活、快速地对接LLM模型，帮助开发者可以快速落地AI业务。</p><h3 id="1-Kernel"><a href="#1-Kernel" class="headerlink" title="1. Kernel"></a><strong>1. Kernel</strong></h3><p><img src="https://picx.zhimg.com/80/v2-9daba1e0791e6fb0bda2a39cf98a0d22_1440w.png?source=d16d100b" alt="img"></p><p>添加图片注释，不超过 140 字（可选）</p><p>kernel都包含哪些？</p><h4 id="上下文"><a href="#上下文" class="headerlink" title="上下文"></a><strong>上下文</strong></h4><p>主要包含三部分：</p><p>ContextVariables，用来存储LLM中间返回结果，是一个全局的运行时变量存储，方便各agent或各skfunction进行引用。</p><p>SemanticTextMemory：管理内存，这里可以类比向量化数据库。</p><p>ReadOnlySkillCollection 管理注册的skill与function这些元数据。</p><h4 id="SkFunction"><a href="#SkFunction" class="headerlink" title="SkFunction"></a><strong>SkFunction</strong></h4><p>SKFunction是一个具体功能的描述，包含 description、prompt、以及大模型相关的参数配置项，比如温度值等</p><p>skill是一组function功能的集合</p><h4 id="Planner"><a href="#Planner" class="headerlink" title="Planner"></a><strong>Planner</strong></h4><p>对解决一个复杂场景问题，结合一堆function，设定一个goal，给出LLM思考逻辑，生成具体执行计划，然后调用skfunction</p><h4 id="PlugIn"><a href="#PlugIn" class="headerlink" title="PlugIn"></a><strong>PlugIn</strong></h4><p>与真实世界进行对接，让LLM有“联网”的能力，可以是API接口，也可以是向量数据库、也可以是本地函数等等。</p><h3 id="2-Demo实践"><a href="#2-Demo实践" class="headerlink" title="2. Demo实践"></a><strong>2. Demo实践</strong></h3><p>代码：官网上下载的JAVA版本</p><h4 id="基础的问答"><a href="#基础的问答" class="headerlink" title="基础的问答"></a><strong>基础的问答</strong></h4><ol><li><strong>kernel构建</strong></li></ol><figure class="highlight reasonml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs reasonml">public static Kernel get<span class="hljs-constructor">Kernel(OpenAIProxyClient <span class="hljs-params">client</span>)</span> &#123;<br>        Kernel kernel = <span class="hljs-module-access"><span class="hljs-module"><span class="hljs-identifier">SKBuilders</span>.</span></span>kernel<span class="hljs-literal">()</span><br>                .<span class="hljs-keyword">with</span><span class="hljs-constructor">DefaultAIService(SKBuilders.<span class="hljs-params">chatCompletion</span>()</span><br>                        .<span class="hljs-keyword">with</span><span class="hljs-constructor">ModelId(<span class="hljs-string">&quot;gpt-3.5-turbo&quot;</span>)</span><br>                        .<span class="hljs-keyword">with</span><span class="hljs-constructor">OpenAIClient(<span class="hljs-params">client</span>)</span><br>                        .build<span class="hljs-literal">()</span>)<br>                .build<span class="hljs-literal">()</span>;<br><br>        return kernel;<br>    &#125;<br></code></pre></td></tr></table></figure><ol><li><strong>skill和function编写，提示词和gpt参数设置</strong></li></ol><p><img src="https://pic1.zhimg.com/80/v2-d5c34467c0e87752dcdc080c412e11e7_1440w.png?source=d16d100b" alt="img"></p><p>添加图片注释，不超过 140 字（可选）</p><ol><li><strong>引入skill与function</strong></li></ol><figure class="highlight pgsql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs pgsql">ReadOnlyFunctionCollection skill = kernel.importSkillFromDirectory(&quot;FunSkill&quot;, SampleSkillsUtil.detectSkillDirLocation(), &quot;FunSkill&quot;);<br><br>        CompletionSKFunction <span class="hljs-keyword">function</span> = skill.getFunction(&quot;Joke&quot;,<br>                CompletionSKFunction.<span class="hljs-keyword">class</span>);<br><br>        Mono&lt;SKContext&gt; result = <span class="hljs-keyword">function</span>.invokeAsync(&quot;赵本山和宋丹丹要在2024年出一个小品&quot;);<br><br>        <span class="hljs-keyword">if</span> (result != <span class="hljs-keyword">null</span>) &#123;<br>            <span class="hljs-keyword">System</span>.<span class="hljs-keyword">out</span>.println(result.block().getResult());<br>        &#125;<br></code></pre></td></tr></table></figure><h4 id="多Agent执行完成一个目标"><a href="#多Agent执行完成一个目标" class="headerlink" title="多Agent执行完成一个目标"></a><strong>多Agent执行完成一个目标</strong></h4><p>以Example_PlanWithNativeFunctions 为例子，这个例子接收用户指令：给Steven发一封邮件，并且有限使用Steven的备注名，具体的函数有：<strong>Emailer 邮件功能</strong> 、<strong>寻找人名的备注名称、以及字符串替换的功能</strong></p><ol><li><strong>Plan通用思考提示词（SK系统）</strong></li></ol><figure class="highlight n1ql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs n1ql">To <span class="hljs-keyword">create</span> a plan, follow these steps:<br><span class="hljs-number">0.</span> The plan should be <span class="hljs-keyword">as</span> short <span class="hljs-keyword">as</span> possible.<br><span class="hljs-number">1.</span> <span class="hljs-keyword">From</span> a &lt;goal&gt; <span class="hljs-keyword">create</span> a &lt;plan&gt; <span class="hljs-keyword">as</span> a series of &lt;functions&gt;.<br><span class="hljs-number">2.</span> Before <span class="hljs-keyword">using</span> <span class="hljs-keyword">any</span> <span class="hljs-keyword">function</span> <span class="hljs-keyword">in</span> a plan, check that it <span class="hljs-keyword">is</span> present <span class="hljs-keyword">in</span> the most recent [AVAILABLE FUNCTIONS] list. <span class="hljs-keyword">If</span> it <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span>, <span class="hljs-keyword">do</span> <span class="hljs-keyword">not</span> <span class="hljs-keyword">use</span> it. <span class="hljs-keyword">Do</span> <span class="hljs-keyword">not</span> assume that <span class="hljs-keyword">any</span> <span class="hljs-keyword">function</span> that was previously defined <span class="hljs-keyword">or</span> used <span class="hljs-keyword">in</span> another plan <span class="hljs-keyword">or</span> <span class="hljs-keyword">in</span> [EXAMPLES] <span class="hljs-keyword">is</span> automatically available <span class="hljs-keyword">or</span> compatible <span class="hljs-keyword">with</span> the current plan.<br><span class="hljs-number">3.</span> Only <span class="hljs-keyword">use</span> functions that are required <span class="hljs-keyword">for</span> the given goal.<br><span class="hljs-number">4.</span> A <span class="hljs-keyword">function</span> has a single <span class="hljs-string">&#x27;input&#x27;</span> <span class="hljs-keyword">and</span> a single <span class="hljs-string">&#x27;output&#x27;</span> which are both strings <span class="hljs-keyword">and</span> <span class="hljs-keyword">not</span> objects.<br><span class="hljs-number">5.</span> The <span class="hljs-string">&#x27;output&#x27;</span> <span class="hljs-keyword">from</span> <span class="hljs-keyword">each</span> <span class="hljs-keyword">function</span> <span class="hljs-keyword">is</span> automatically passed <span class="hljs-keyword">as</span> <span class="hljs-string">&#x27;input&#x27;</span> <span class="hljs-keyword">to</span> the subsequent &lt;<span class="hljs-keyword">function</span>&gt;.<br><span class="hljs-number">6.</span> <span class="hljs-string">&#x27;input&#x27;</span> does <span class="hljs-keyword">not</span> need <span class="hljs-keyword">to</span> be specified <span class="hljs-keyword">if</span> it consumes the <span class="hljs-string">&#x27;output&#x27;</span> of the previous <span class="hljs-keyword">function</span>.<br><span class="hljs-number">7.</span> <span class="hljs-keyword">To</span> save an <span class="hljs-string">&#x27;output&#x27;</span> <span class="hljs-keyword">from</span> a &lt;<span class="hljs-keyword">function</span>&gt;, <span class="hljs-keyword">to</span> pass <span class="hljs-keyword">into</span> a future &lt;<span class="hljs-keyword">function</span>&gt;, <span class="hljs-keyword">use</span> &lt;<span class="hljs-keyword">function</span>.&#123;FunctionName&#125; ... setContextVariable: <span class="hljs-string">&quot;&lt;UNIQUE_VARIABLE_KEY&gt;&quot;</span>/&gt;<br><span class="hljs-number">8.</span> <span class="hljs-keyword">To</span> save an <span class="hljs-string">&#x27;output&#x27;</span> <span class="hljs-keyword">from</span> a &lt;<span class="hljs-keyword">function</span>&gt;, <span class="hljs-keyword">to</span> <span class="hljs-keyword">return</span> <span class="hljs-keyword">as</span> part of a plan result, <span class="hljs-keyword">use</span> &lt;<span class="hljs-keyword">function</span>.&#123;FunctionName&#125; ... appendToResult: <span class="hljs-string">&quot;RESULT__&lt;UNIQUE_RESULT_KEY&gt;&quot;</span>/&gt;<br><span class="hljs-number">9.</span> Append an <span class="hljs-string">&quot;END&quot;</span> XML comment at the <span class="hljs-keyword">end</span> of the plan<br></code></pre></td></tr></table></figure><ol><li><strong>生成执行计划–XML文件（SK系统）</strong></li></ol><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs routeros">&lt;function.Names.getNickName <span class="hljs-attribute">input</span>=<span class="hljs-string">&quot;Steven&quot;</span> <span class="hljs-attribute">setContextVariable</span>=<span class="hljs-string">&quot;NICKNAME&quot;</span>/&gt;<br>  &lt;function.StringFunctions.stringReplace <span class="hljs-attribute">from</span>=<span class="hljs-string">&quot;USER_NAME&quot;</span> <span class="hljs-attribute">input</span>=<span class="hljs-string">&quot;Hello, USER_NAME. This is an important message for you.&quot;</span> <span class="hljs-attribute">to</span>=<span class="hljs-string">&quot;<span class="hljs-variable">$NICKNAME</span>&quot;</span> <span class="hljs-attribute">setContextVariable</span>=<span class="hljs-string">&quot;REPLACED_MESSAGE&quot;</span>/&gt;<br>  &lt;function.Emailer.getEmailAddress <span class="hljs-attribute">input</span>=<span class="hljs-string">&quot;Steven&quot;</span> <span class="hljs-attribute">setContextVariable</span>=<span class="hljs-string">&quot;EMAIL_ADDRESS&quot;</span>/&gt;<br>  &lt;function.Emailer.sendEmail <span class="hljs-attribute">emailaddress</span>=<span class="hljs-string">&quot;<span class="hljs-variable">$EMAIL_ADDRESS</span>&quot;</span> <span class="hljs-attribute">message</span>=<span class="hljs-string">&quot;<span class="hljs-variable">$REPLACED_MESSAGE</span>&quot;</span> <span class="hljs-attribute">subject</span>=<span class="hljs-string">&quot;Important Message&quot;</span>/&gt;<br></code></pre></td></tr></table></figure><ol><li><strong>定义每个SKFunction的功能以及接收的输入参数（用户自定义）</strong></li></ol><figure class="highlight typescript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs typescript"><span class="hljs-meta">@DefineSKFunction</span>(name = <span class="hljs-string">&quot;getEmailAddress&quot;</span>, description = <span class="hljs-string">&quot;Retrieves the email address for a given user&quot;</span>)<br>        <span class="hljs-keyword">public</span> <span class="hljs-title class_">String</span> <span class="hljs-title function_">getEmailAddress</span>(<span class="hljs-params"></span><br><span class="hljs-params">                <span class="hljs-meta">@SKFunctionInputAttribute</span>(description = <span class="hljs-string">&quot;The name of the person to get an email address for&quot;</span>)</span><br><span class="hljs-params">                <span class="hljs-built_in">String</span> name</span>) &#123;<br>            <span class="hljs-keyword">switch</span> (name) &#123;<br>                <span class="hljs-keyword">case</span> <span class="hljs-string">&quot;Steven&quot;</span>:<br>                    <span class="hljs-keyword">return</span> <span class="hljs-string">&quot;codeking@example.com&quot;</span>;<br>                <span class="hljs-attr">default</span>:<br>                    <span class="hljs-keyword">throw</span> <span class="hljs-keyword">new</span> <span class="hljs-title class_">RuntimeException</span>(<span class="hljs-string">&quot;Unknown user: &quot;</span> + name);<br>            &#125;<br>        &#125;<br></code></pre></td></tr></table></figure><ol><li><strong>使用Plan进行调用</strong></li></ol><figure class="highlight reasonml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs reasonml">kernel.import<span class="hljs-constructor">Skill(<span class="hljs-params">new</span> StringFunctions()</span>, <span class="hljs-string">&quot;StringFunctions&quot;</span>);<br>kernel.import<span class="hljs-constructor">Skill(<span class="hljs-params">new</span> Emailer()</span>, <span class="hljs-string">&quot;Emailer&quot;</span>);<br>kernel.import<span class="hljs-constructor">Skill(<span class="hljs-params">new</span> Names()</span>, <span class="hljs-string">&quot;Names&quot;</span>);<br><br>SequentialPlanner planner = <span class="hljs-keyword">new</span> <span class="hljs-constructor">SequentialPlanner(<span class="hljs-params">kernel</span>, <span class="hljs-params">null</span>, <span class="hljs-params">null</span>)</span>;<br><br><br>Plan plan = planner<br>.create<span class="hljs-constructor">PlanAsync(<span class="hljs-string">&quot;Send the input as an email to Steven and make sure I use his preferred name in the email&quot;</span>)</span><br>.block<span class="hljs-literal">()</span>;<br></code></pre></td></tr></table></figure><h3 id="3-思考"><a href="#3-思考" class="headerlink" title="3. 思考"></a><strong>3. 思考</strong></h3><p>与LangChain的对比</p><table><thead><tr><th></th><th>LangChain</th><th>Semantic Kernel</th></tr></thead><tbody><tr><td>开发组织</td><td>社区</td><td>微软</td></tr><tr><td>设计理念</td><td>Model I&#x2F;O 、 Retriver、Chain、Memory</td><td>Kernel、SKFunction、ContextVar、Plan、Plugin</td></tr><tr><td>支持语言</td><td>python</td><td>python&#x2F;c#&#x2F;java，主推python与c#</td></tr><tr><td>社区活跃</td><td>活跃，功能迭代很快</td><td>比LangChain慢</td></tr><tr><td>生态集成</td><td>集成了各种Model I&#x2F;O</td><td>生态集成没有LangChain高</td></tr><tr><td>记忆能力</td><td>支持</td><td>支持</td></tr><tr><td>支持多LLM切换</td><td>支持</td><td>支持</td></tr><tr><td>RAG支持</td><td>支持Retriver</td><td>支持Memory</td></tr><tr><td>Agent支持</td><td>支持</td><td>支持</td></tr><tr><td>多Agent支持</td><td>支持LangGraph</td><td>支持Planner</td></tr></tbody></table><h3 id="4-其他思考"><a href="#4-其他思考" class="headerlink" title="4. 其他思考"></a>4. <strong>其他思考</strong></h3><p>Semantic kernel 的function与planner 抽象的比较好，可以通过planner来实现复杂场景的企业级AI应用。LangChain更适合快速落地一个AI应用，已经沉淀了各种Chain，拿来即用。同时LangChain已经推出LangGraph了，已经在实现类似Planner的功能。</p><h2 id="Embeding技术"><a href="#Embeding技术" class="headerlink" title="Embeding技术"></a><strong>Embeding技术</strong></h2><h3 id="1-介绍"><a href="#1-介绍" class="headerlink" title="1. 介绍"></a><strong>1. 介绍</strong></h3><p>将现实世界中的信息映射到低维的向量空间上。机器学习训练中的一个环节，在大模型产生之前就已经有了。</p><h3 id="2-应用场景"><a href="#2-应用场景" class="headerlink" title="2. 应用场景"></a><strong>2. 应用场景</strong></h3><h4 id="RAG向量召回场景"><a href="#RAG向量召回场景" class="headerlink" title="RAG向量召回场景"></a><strong>RAG向量召回场景</strong></h4><p><img src="https://picx.zhimg.com/80/v2-069230cff445aa6ce54cfd682623e812_1440w.jpg?source=d16d100b" alt="img"></p><p>添加图片注释，不超过 140 字（可选）</p><p>RAG使用中的场景</p><h4 id="机器学习训练特征提取"><a href="#机器学习训练特征提取" class="headerlink" title="机器学习训练特征提取"></a><strong>机器学习训练特征提取</strong></h4><p>降维、特征提取、数据压缩等</p><h3 id="3-如何生成向量"><a href="#3-如何生成向量" class="headerlink" title="3. 如何生成向量"></a><strong>3. 如何生成向量</strong></h3><p><strong>常用embedding技术</strong></p><p>一般分为在线服务和离线服务</p><p><a href="https://huggingface.co/spaces/mteb/leaderboard%E8%BF%99%E4%B8%AA%E7%BD%91%E7%AB%99%E4%BB%8B%E7%BB%8D%E4%BA%86%E5%BD%93%E5%89%8D%E4%B8%BB%E6%B5%81%E7%9A%84%E4%B8%80%E4%BA%9Bembedding%E6%8A%80%E6%9C%AF%E4%BB%A5%E5%8F%8A%E6%8E%92%E8%A1%8C%E6%A6%9C%E6%83%85%E5%86%B5%E3%80%82">https://huggingface.co/spaces/mteb/leaderboard这个网站介绍了当前主流的一些embedding技术以及排行榜情况。</a></p><p>目前了解到的一些embedding技术包括：Word2Vec、通义千问embedding、text-embedding-3-small and text-embedding-3-large <a href="https://platform.openai.com/docs/guides/embeddings/what-are-embeddings">openAI embedding</a></p><p><strong>图像embedding</strong></p><p>一般用于图像分类、目标检测、计算机视觉等，不详细展开。</p><p><strong>视频embedding</strong></p><p>一般用于视频检索、视频内容理解、视频推荐等，不详细展开</p><h3 id="4-如何计算相似度"><a href="#4-如何计算相似度" class="headerlink" title="4. 如何计算相似度"></a><strong>4. 如何计算相似度</strong></h3><p>欧几里得距离</p><p><img src="https://pic1.zhimg.com/80/v2-e441bbd7f8e5eab87e94f99f5719e82e_1440w.jpg?source=d16d100b" alt="img"></p><p>添加图片注释，不超过 140 字（可选）</p><p>余弦距离</p><p><img src="https://picx.zhimg.com/80/v2-92c959d665fd0523f99f1eb37d5daca1_1440w.jpg?source=d16d100b" alt="img"></p><p>添加图片注释，不超过 140 字（可选）</p><p>曼哈顿距离</p><p><img src="https://picx.zhimg.com/80/v2-e8838f2a88a955927ae3b379ea0a10ba_1440w.jpg?source=d16d100b" alt="img"></p><p>添加图片注释，不超过 140 字（可选）</p><h3 id="5-代码示例"><a href="#5-代码示例" class="headerlink" title="5. 代码示例"></a><strong>5. 代码示例</strong></h3><p>文本：“你是谁”？</p><p>方法：通义千问在线embedding</p><p>结果：</p><p><img src="https://picx.zhimg.com/80/v2-71319122f67b1ce1786ca70ef3b3ab6a_1440w.jpg?source=d16d100b" alt="img"></p><p>添加图片注释，不超过 140 字（可选）</p><p>1500+维度的空间向量</p><h3 id="6-思考"><a href="#6-思考" class="headerlink" title="6. 思考"></a><strong>6. 思考</strong></h3><p>1.Embedding作为召回策略中的一种，不同的embedding模型可能会对召回产生不同的影响，最好与LLM本身采用的embedding技术保持一致。</p><p>2.向量召回只是RAG召回策略中的一种，还包括搜索召回等其他方法。</p><h2 id="微调技术"><a href="#微调技术" class="headerlink" title="微调技术"></a><strong>微调技术</strong></h2><h3 id="1-背景"><a href="#1-背景" class="headerlink" title="1. 背景"></a>1. 背景</h3><p>最近尝试了<strong>RAG技术</strong>实现了基于LLM上的智能答疑，也尝试了工作流的生成，发现效果严重依赖于大模型的能力，同时好的大模型成本又比较高，每次调用需要从知识库中召回大量的文档，从而消耗大量的token，所以在思考是否可以尝试通过将这些文档微调到大模型上。同时在思考是否也不需要超大参数的模型，是否可以基于小模型和业务数据来微调出自己的业务垂直模型。</p><p>同时我发现微调也没那么容易上手，因为这对于将来模型调试后的效果还是挺重要的，同时，理解一点基础的原理还是有必要的，仅仅是参照网上的教程一步步执行命令行，不晓得其中的原理，很容易一头雾水。</p><h3 id="2-什么是预训练模型"><a href="#2-什么是预训练模型" class="headerlink" title="2. 什么是预训练模型"></a><strong>2. 什么是预训练模型</strong></h3><p>其实在之前已经有预训练模型的一些概念了。比如CNN、RNN等。其大概原理是每次训练，与目标值计算得出损失值，反向传播驱动模型迭代更新，使得下一代迭代更精确。</p><p><strong>CNN</strong>：适合于图像领域</p><p><strong>RNN</strong>：适合于自然语言NLP</p><p><strong>Transformer</strong>模型：基于RNN之上增加了并行处理和注意力机制的特性。</p><h3 id="3-什么是微调"><a href="#3-什么是微调" class="headerlink" title="3. 什么是微调"></a><strong>3. 什么是微调</strong></h3><p><strong>在已经训练好的大模型基础上，使用特定的数据集进行进一步的训练，以使模型适应特定任务或领域</strong>。有一个例子解释的挺好：小明刚刚学会了开车，那么他已经掌握了一些基础的开车技巧，比如起步、踩油门、转弯、换挡、靠边停车等一些基础技能。在微调的过程中，小明要适应在湿滑的泥地、大雾天气、山路陡坡、雨雪天等场景下开车，以适应新的场地要求。</p><h3 id="4-什么情况下微调"><a href="#4-什么情况下微调" class="headerlink" title="4. 什么情况下微调"></a><strong>4. 什么情况下微调</strong></h3><p>训练自己垂直领域的大模型，以适应自己特定领域的任务， 但是<strong>数据规模小，同时计算资源又稀缺</strong>。</p><h3 id="5-为什么会有不同的微调方法？"><a href="#5-为什么会有不同的微调方法？" class="headerlink" title="5. 为什么会有不同的微调方法？"></a><strong>5. 为什么会有不同的微调方法？</strong></h3><p>假设我们把训练过程简单定义为：Y（真实结果）&#x3D;W（模型）*X（输入）</p><p>Y&#x3D;[y1,y2,y3,y4,y5…yn] X&#x3D;[x1,x,2,x3,…xm]，Y和X是Embeding之后的矩阵向量，那么最后优化的就是这个W。</p><p>那么对于新的数据集X和Y，如何优化W，一种办法是W中加入一些低纬度的矩阵权重，另一种办法是X做一些演变，根据数据集去优化W。以下就是几种方法的基本原理。</p><h3 id="6-几种方法"><a href="#6-几种方法" class="headerlink" title="6. 几种方法"></a><strong>6. 几种方法</strong></h3><p><strong>LoRA</strong></p><p>新权重 &#x3D; 原始权重 + AB。</p><p>Y &#x3D;(W*@W)*X</p><p>数学上的含义：假设 预训练模型是训练中间的神经网络，我们把最终生成的这个“神经网络” 比喻成是矩阵<strong>变换A X 矩阵变化B X 矩阵变化C</strong> ….，那么最终生成的预训练模型就是超大规模的矩阵变化集合。那么微调就是在这个超大规模的矩阵变化中，加入一些<strong>低纬度的矩阵变化</strong>，通过训练给入的小规模入参，优化这些低纬度的矩阵变化过程，最终来适应这个特定领域的“逻辑”</p><p><strong>Prompt Tuning</strong></p><p>Y &#x3D; WX&#96;</p><p>就是在输入端加入一些提示词，以增大生成期望结果的概率。简单来说：给定预训练模型的参数，然后在模型的输入端添加可学习的”prompt”（提示）进行调整</p><h3 id="7-部署教程"><a href="#7-部署教程" class="headerlink" title="7. 部署教程"></a><strong>7. 部署教程</strong></h3><h3 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a><strong>参考资料</strong></h3><p><a href="https://www.heywhale.com/mw/project/6436d82948f7da1fee2be59e">https://www.heywhale.com/mw/project/6436d82948f7da1fee2be59e</a></p><p>准备工作： 数据集、微调训练方法 P-tuning v2</p><p>基础环境：GPU、pyTorch、模型文件、数据集文件</p><p>验证：使用Langchain进行简单测试验证。</p>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>03-AI技术-LLMAgent学习笔记</title>
    <link href="/2024/01/07/03-LLMAgent%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    <url>/2024/01/07/03-LLMAgent%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/</url>
    
    <content type="html"><![CDATA[<p>上文介绍了LangChain的基本原理，但是越来越发现Agent的重要性</p><h1 id="Agent基本概念"><a href="#Agent基本概念" class="headerlink" title="Agent基本概念"></a>Agent基本概念</h1><p>Planning</p><p>Thinking</p><p>Action</p><p>Memory</p><h1 id="多Agent-Framework"><a href="#多Agent-Framework" class="headerlink" title="多Agent Framework"></a>多Agent Framework</h1><p>MetaGPT</p><img src="https://docs.deepwisdom.ai/main/image/guide/tutorials/multi_agents_flowchart.png" alt="img" style="zoom: 33%;" /><p>核心的元素：观察、提示词+工具、返回结果集成到上下文中。</p><h1 id="semantic-kernel"><a href="#semantic-kernel" class="headerlink" title="semantic kernel"></a>semantic kernel</h1><p>是微软开发的一个基于LLM之上的开发框架，与Langchain类似。但是它从设计上就将function 和prompt 作为一个kerne作为一个原子操作。所以，天然就支持这种workflow的概念。</p><h1 id="GPT-STORE"><a href="#GPT-STORE" class="headerlink" title="GPT STORE"></a>GPT STORE</h1><h2 id="应用市场"><a href="#应用市场" class="headerlink" title="应用市场"></a>应用市场</h2> <img src="/images/chatgpt_store.png" alt="img" style="zoom:20%;" /><h2 id="构建应用"><a href="#构建应用" class="headerlink" title="构建应用"></a>构建应用</h2><ol><li>构建自己的GPT应用</li></ol><img src="/images/chatGPT_builder_configure.png" alt="img" style="zoom:20%;" /><ol start="2"><li>知识库&#x2F;能力&#x2F;外部action能力配置</li></ol><img src="/images/chatGPT_builder_configure_2.png" alt="img" style="zoom:20%;" /><ol start="3"><li><p>action配置的能力</p><p>语法像semantic kernel的语法</p></li></ol><img src="/images/chatGPT_builder_action.png" alt="img" style="zoom:20%;" />]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>自动化测试</title>
    <link href="/2023/12/23/%E8%87%AA%E5%8A%A8%E5%8C%96%E6%B5%8B%E8%AF%95/"/>
    <url>/2023/12/23/%E8%87%AA%E5%8A%A8%E5%8C%96%E6%B5%8B%E8%AF%95/</url>
    
    <content type="html"><![CDATA[<h3 id="流量采集"><a href="#流量采集" class="headerlink" title="流量采集"></a>流量采集</h3><p>关键技术：采样率</p><h3 id="测试用例管理"><a href="#测试用例管理" class="headerlink" title="测试用例管理"></a>测试用例管理</h3><h3 id="用例重放-amp-测试报告"><a href="#用例重放-amp-测试报告" class="headerlink" title="用例重放&amp;测试报告"></a>用例重放&amp;测试报告</h3><p>断言、返回结果数据分析</p>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>02-AI技术-LangChain原理解析</title>
    <link href="/2023/12/20/02-langchain/"/>
    <url>/2023/12/20/02-langchain/</url>
    
    <content type="html"><![CDATA[<p>最新越发觉得AI的发展，对未来是一场革命，LangChain已经在工程设计上有了最佳实践，类似于AI时代的编程模型或编程框架，有点Spring框架的意思。之前在LangChain上也有些最佳实践，所以在这里分享记录下。</p><h3 id="LangChain属于哪一层"><a href="#LangChain属于哪一层" class="headerlink" title="LangChain属于哪一层"></a>LangChain属于哪一层</h3><p>​    LangChain是基于LLM之上的，在应用层和底层LLM之前的一个很好的编程框架，如果把LLM比喻为各种类型的数据库、中间件等这些基础设施，应用层是各种业务逻辑的组合之外，那么LangChain就负责桥接与业务层和底层LLM模型，让开发者可以快速地实现对接各种底层模型和快速实现业务逻辑的软件开发框架。</p><p>   那么LangChain是如何做到的呢？试想一下，现在底层有一个大模型的推理能力，除了在对话框手动输入跟他聊天之外。如何用计算机方式跟它互动呢？如果把一次LLM调用当作一个原子能力，如何编排这些原子能力来解决一些业务需求呢？Langchain就是来解决这个事情的。</p><h3 id="LangChain的几个核心概念"><a href="#LangChain的几个核心概念" class="headerlink" title="LangChain的几个核心概念"></a>LangChain的几个核心概念</h3><h4 id="格式化数据（I-x2F-O）"><a href="#格式化数据（I-x2F-O）" class="headerlink" title="格式化数据（I&#x2F;O）"></a>格式化数据（I&#x2F;O）</h4><h4 id="Retriver"><a href="#Retriver" class="headerlink" title="Retriver"></a>Retriver</h4><p>   检索是为了解决大模型打通用户的本身数据，做一些面向业务属性的东西。这里的检索并非传统的关系型数据库，更多的是与大模型的本身逻辑相似的，比如向量数据库。</p><h5 id="一个经典的结合LLM和外部用户的文档进行智能答疑的场景"><a href="#一个经典的结合LLM和外部用户的文档进行智能答疑的场景" class="headerlink" title="一个经典的结合LLM和外部用户的文档进行智能答疑的场景"></a>一个经典的结合LLM和外部用户的文档进行智能答疑的场景</h5><p>文档-&gt;分词-&gt;embedding-&gt;向量数据库</p><p>query-&gt;向量数据库查询-&gt;TOP N-&gt;上下文+ 用户提问 + prompt -&gt; LLM -&gt; 返回结果</p><p>一个经典的图如下：</p><img src="/images/langchain_chatglm.png" alt="img" style="zoom:20%;" /><p><strong>关键技术：文档如何拆分、embedding过程、 TOPN 向量距离的选择</strong></p><p>embedding技术选型</p><p> embedding是将现实中的物体通过向量化的方法转化为高维向量，可被机器学习模型所识别。他是一种映射，同时也保证了能清晰地表达现实物体的特征。基于此，可以进行一些归类分析、回归分析等。</p><p>现在市面上常见的embedding方法有通义千问的embedding等方法。</p><p>向量数据库</p><p>​     向量数据库底层存储的是一堆向量，它提供了根据向量相似度进行查询的能力，一般情况下，向量相似度代表了现实世界中物体的相似度。比如”我的名字是小明“ 和“我叫小明”这两句话所代表的含义几乎是相同的，那么在embedding之后，基于向量数据库进行查询的时候，它们俩的相似度就会很近。</p><p>现在市面上常见的向量数据库有xxx</p><h4 id="Chain"><a href="#Chain" class="headerlink" title="Chain"></a>Chain</h4><p>各种类型的chain，chain代表了各种业务类型的组合，类似于工作流的编排。</p><h4 id="Memory"><a href="#Memory" class="headerlink" title="Memory"></a>Memory</h4><p>LLM本身提供了记忆的能力，同时提供了接口，开发者可以将历史的对话记录传入给LLM。LangChain需要使用外部存储保存这些历史的会话和记忆。可以使用数据库、缓存等进行保存。</p><h4 id="Agent"><a href="#Agent" class="headerlink" title="Agent"></a>Agent</h4><h5 id="重点是代理工具"><a href="#重点是代理工具" class="headerlink" title="重点是代理工具"></a>重点是代理工具</h5><p>   代理工具可以让应用程序基于大模型的推理能力，然后进行代理工具或代理服务的调用。因为LLM是没有“联网”的能力的，如果想解决特定的应用场景，代理工具是个完美的选择。</p><p>代理工具通常包含三个方面： 用户输入、prompt编排LLM思考与路由代理的过程、背后的代理服务。其中难点可能就在于prompt设计了。通常的“套路”是这样的：</p><h5 id="ReAct-模型："><a href="#ReAct-模型：" class="headerlink" title="ReAct 模型："></a>ReAct 模型：</h5><p>输入：用户的问题</p><p>思考过程：如果是情况1（这个是需要LLM进行意图识别进行思考的），那么推理和提取出一些关键参数，调用agent1，如果是情况2，那么推理和提取出一些关键参数，调用agent2</p><p>Act：调用agent1对应一个JSON格式化的输入，调用function1，返回结果。</p><p>观察：观察调用后的结果，再结合推理的能力，再进行循环思考。</p><h3 id="LangChain的在实际场景中的实践"><a href="#LangChain的在实际场景中的实践" class="headerlink" title="LangChain的在实际场景中的实践"></a>LangChain的在实际场景中的实践</h3><h4 id="智能问答"><a href="#智能问答" class="headerlink" title="智能问答"></a>智能问答</h4><p>Embedding 是将FAQ的知识库</p><p>prompt+embedding+ 向量数据库+agent </p><h4 id=""><a href="#" class="headerlink" title=""></a></h4>]]></content>
    
    
    
    <tags>
      
      <tag>AI,LangChain,LLM</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>05-消息队列-kafka脑裂问题</title>
    <link href="/2023/12/20/kafka%E8%84%91%E8%A3%82%E9%97%AE%E9%A2%98/"/>
    <url>/2023/12/20/kafka%E8%84%91%E8%A3%82%E9%97%AE%E9%A2%98/</url>
    
    <content type="html"><![CDATA[<h2 id="什么是脑裂？"><a href="#什么是脑裂？" class="headerlink" title="什么是脑裂？"></a>什么是脑裂？</h2><p>​     脑裂是分布式系统高可用（High Avaliablity）场景下容易出现的问题。我们知道，在分布式系统中常常用多副本来解决容错性问题，多副本中会选举出一个Leader负责与客户端进行交互，但由于各种原因分布式集群中会出现脑裂的情况</p><p>zookeeper脑裂问题 - tantexian的博客空间 - OSCHINAmy.oschina.net&#x2F;tantexian&#x2F;blog&#x2F;2876309</p><p> 这篇文章给出了详细的解释。这里再简单概述以下，基本上是由于网络或者其他原因导致master出现假死，这时候会触发系统进行新的master选举，此时系统中就会出现两个master，产生一系列问题。</p><h2 id="什么是kafka-controller？"><a href="#什么是kafka-controller？" class="headerlink" title="什么是kafka controller？"></a>什么是kafka controller？</h2><p>​    kafka controller相当于整个kafka集群的<strong>master</strong>，负责topic的创建、删除、以及partition的状态机转换，broker的上线、下线等。那么controller是如何选举出来的呢？它是通过抢占方式在zookeeper上注册临时节点来实现的，第一个注册成功的即为controller。关键之处来了，由于<strong>zookeeper临时节点的有效性是通过session来判断的，若在session timeout时间内，controller所在的broker断掉，则会触发新的controller选举。</strong></p><h2 id="kafka-Controller脑裂带来什么问题？"><a href="#kafka-Controller脑裂带来什么问题？" class="headerlink" title="kafka Controller脑裂带来什么问题？"></a>kafka Controller脑裂带来什么问题？</h2><p>什么服务会受到影响？Topic元数据信息新增或者改变时，会在对应的zookeeper path下添加或者更新数据，而controller都对这个路径进行了watch，当有数据变化时，controller会进行partition、replica state的转化，进而对所有存活的broker发送LeaderISR请求，这时第二个controller会发生错误，进而元数据更新失败，对应的partition无法变为online状态。</p><ol><li>创建新的topic成功，客户端往topic内写数据时； </li><li>给某个topic增加分区，zk显示已有增加的分区信息，但是依旧报找不到新增加的分区信息错误</li></ol><p>什么服务不会受到影响？</p><p>  现有的topic读写不受影响，因为读写时获取partition的元数据信息在任意broker上都可以获取到</p><h2 id="什么情况下会导致这个问题？如何解决？"><a href="#什么情况下会导致这个问题？如何解决？" class="headerlink" title="什么情况下会导致这个问题？如何解决？"></a>什么情况下会导致这个问题？如何解决？</h2><ol><li>Controller进行Full GC停顿时间太长超过zookeeper session timeout 出现假死</li><li>Controller 所在broker网络出现故障</li></ol><p>解决方案1：在zk上找到最新的controller所在的broker， 将其余几个过期的controller重启，找其余controller办法，通过上图jmx指标获取value&#x3D;1的 broker</p><p><img src="https://picx.zhimg.com/80/v2-071a5a1f9984922f258d09c589c40ad0_1440w.png?source=d16d100b" alt="img"></p><p>添加图片注释，不超过 140 字（可选）</p><p>解决方案2:</p><p>升级新版本，新版本解决了这个BUG</p>]]></content>
    
    
    
    <tags>
      
      <tag>稳定性</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>hexo</title>
    <link href="/2023/12/20/hexo/"/>
    <url>/2023/12/20/hexo/</url>
    
    <content type="html"><![CDATA[<p>Hexo 是一个基于 Node.js 的静态博客框架，允许你使用 Markdown 编写文章，然后通过 Hexo 生成静态网页。以下是一些常用的 Hexo 命令：</p><p>初始化博客：</p><p>bash<br>Copy code<br>hexo init <folder><br>cd <folder><br>用于在指定文件夹中初始化一个 Hexo 博客。</p><p>生成静态文件：</p><p>bash<br>Copy code<br>hexo generate<br>用于将 Markdown 文件转换为静态 HTML 文件。</p><p>启动本地服务器：</p><p>bash<br>Copy code<br>hexo server<br>用于启动一个本地服务器，可以在浏览器中预览生成的静态网页。默认地址是 <a href="http://localhost:4000。">http://localhost:4000。</a></p><p>新建文章：</p><p>bash<br>Copy code<br>hexo new [layout] <title><br>用于新建一篇文章。可选的 layout 参数可以是 post（默认）、page 等。</p><p>部署到远程仓库（如GitHub）：</p><p>bash<br>Copy code<br>hexo deploy<br>用于将生成的静态文件部署到配置好的远程仓库。</p><p>清理缓存文件：</p><p>bash<br>Copy code<br>hexo clean<br>用于清理 Hexo 生成过程中产生的临时文件。</p><p>查看帮助：</p><p>bash<br>Copy code<br>hexo –help<br>用于查看 Hexo 的帮助信息，包括可用命令和选项。</p><p>这些是一些基本的 Hexo 命令，你可以根据需要进一步了解 Hexo 的配置和插件系统以及其他更高级的用法。</p>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>低代码技术</title>
    <link href="/2023/06/11/%E4%BD%8E%E4%BB%A3%E7%A0%81%E6%8A%80%E6%9C%AF/"/>
    <url>/2023/06/11/%E4%BD%8E%E4%BB%A3%E7%A0%81%E6%8A%80%E6%9C%AF/</url>
    
    <content type="html"><![CDATA[<p>低代码在某些场景下的开发效率会很高，比如xxx。因此有必要研究一下低代码场景下的一些核心功能。</p><h2 id="页面"><a href="#页面" class="headerlink" title="页面"></a>页面</h2><p>表单搭建</p><ol><li>Google Forms：<ul><li>优点：简单易用，免费使用，与Google账号和Google Drive无缝集成，可轻松创建各种类型的表单，支持多种问题类型和自定义选项。</li><li>缺点：功能相对较基础，定制性较低，对于复杂的表单需求可能不够满足。</li></ul></li><li>Microsoft Forms：<ul><li>优点：集成于Microsoft Office 365，支持与Microsoft Teams、SharePoint等工具无缝协作，具备丰富的表单设计和逻辑控制功能，易于创建和分享表单。</li><li>缺点：功能相对较简化，仅限于Microsoft Office 365生态系统。</li></ul></li><li>JotForm：<ul><li>优点：提供丰富的表单模板和设计工具，具备强大的表单逻辑和自动化功能，支持在线支付和集成多种第三方应用程序。</li><li>缺点：高级功能需要付费订阅，某些特定功能可能需要额外的配置和集成。</li></ul></li><li>Wufoo：<ul><li>优点：用户友好的界面，提供多种预设计表单模板，支持自定义设计和布局，具备强大的报告和分析功能。</li><li>缺点：部分高级功能需要付费订阅，集成和扩展性相对有限。</li></ul></li><li>Typeform：<ul><li>优点：独特的用户体验，通过交互式设计和动态问答形式创建表单，支持多媒体内容和自定义主题，提供强大的数据分析和可视化功能。</li><li>缺点：某些高级功能和定制选项需要付费订阅，特殊设计可能需要一定的学习曲线。</li></ul></li></ol><h2 id="工作流"><a href="#工作流" class="headerlink" title="工作流"></a>工作流</h2><h3 id="工作流引擎"><a href="#工作流引擎" class="headerlink" title="工作流引擎"></a>工作流引擎</h3><ol><li><p>Apache Airflow: 优点：</p><ul><li>支持可扩展的任务调度和工作流编排，具有高度灵活性。</li><li>提供可视化的用户界面和丰富的插件生态系统。</li><li>具备良好的可编程性和可定制性，适用于复杂的工作流需求。</li></ul><p>缺点：</p><ul><li>部署和配置较为复杂，对于初学者来说有一定的学习曲线。</li><li>可视化界面相对简单，不够直观。</li></ul></li><li><p>Camunda BPM: 优点：</p><ul><li>提供全面的业务流程管理解决方案，具有强大的工作流引擎功能。</li><li>支持复杂的流程编排和规则引擎。</li><li>提供了用户友好的建模工具和监控面板。</li></ul><p>缺点：</p><ul><li>需要一定的开发技能和理解业务流程建模的概念。</li><li>需要额外的配置和集成才能适应特定的环境和需求。</li></ul></li><li><p>IBM Business Automation Workflow: 优点：</p><ul><li>提供完整的工作流和决策管理解决方案，包括流程建模、执行和监控。</li><li>支持高度可扩展的分布式架构和大规模部署。</li><li>具备强大的决策规则引擎和自动化决策能力。</li></ul><p>缺点：</p><ul><li>高度定制化和企业级功能可能会导致复杂性增加。</li><li>相对较高的成本和学习曲线，适用于大型企业和复杂业务场景。</li></ul></li><li><p>Microsoft Power Automate (以前的Microsoft Flow): 优点：</p><ul><li>与Microsoft Office 365和其他Microsoft产品集成紧密，易于使用和配置。</li><li>提供丰富的连接器和模板，便于快速构建常见的工作流程。</li><li>可以通过低代码方式进行自定义扩展。</li></ul><p>缺点：</p><ul><li>功能相对较简化，不适用于复杂的工作流需求。</li><li>集成主要面向Microsoft生态系统，对其他系统和平台的支持有限。</li></ul></li></ol><table><thead><tr><th align="left">工作流引擎</th><th>优点</th><th>缺点</th></tr></thead><tbody><tr><td align="left">Smart-engine</td><td></td><td></td></tr><tr><td align="left"></td><td></td><td></td></tr><tr><td align="left"></td><td></td><td></td></tr></tbody></table><h3 id="工作流搭建"><a href="#工作流搭建" class="headerlink" title="工作流搭建"></a>工作流搭建</h3><h3 id="事件中心"><a href="#事件中心" class="headerlink" title="事件中心"></a>事件中心</h3><p>事件中心一般包括 消息出发、HTTP触发等方式。</p><h3 id="连接器"><a href="#连接器" class="headerlink" title="连接器"></a>连接器</h3><p>连接器一般用来连接工作流和微服务的调用。核心功能有代理执行和参数映射</p><h2 id="工作表"><a href="#工作表" class="headerlink" title="工作表"></a>工作表</h2><p>用来进行用户数据存储。用户数据存储可以用传统的Mysql，也可以用分布式数据库XXX。</p><p>EXCEL导入是一个比较常见的功能，Easy-Excel是一个不错的框架。</p><h3 id="数据空间"><a href="#数据空间" class="headerlink" title="数据空间"></a>数据空间</h3>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>04-消息队列-Kafka原理</title>
    <link href="/2023/05/07/Kafka%E5%8E%9F%E7%90%86/"/>
    <url>/2023/05/07/Kafka%E5%8E%9F%E7%90%86/</url>
    
    <content type="html"><![CDATA[<ul><li><a href="#kafka-%E7%AB%AF%E5%88%B0%E7%AB%AF%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90">Kafka 端到端源码解析</a><ul><li><a href="#kafka%E7%9A%84%E5%9C%BA%E6%99%AF">Kafka的场景</a></li><li><a href="#kafka%E6%A6%82%E5%BF%B5">Kafka概念</a></li><li><a href="#topic-%E5%88%9B%E5%BB%BA%E4%B8%8E%E5%88%A0%E9%99%A4">Topic 创建与删除</a><ul><li><a href="#topic%E7%8A%B6%E6%80%81%E6%B5%81%E8%BD%AC">Topic状态流转</a></li><li><a href="#topic-%E4%B8%80%E4%BA%9B%E9%97%AE%E9%A2%98">一些问题</a></li><li><a href="#topic%E5%88%86%E5%8C%BA%E5%88%9D%E5%A7%8B%E5%8C%96%E9%80%89%E6%8B%A9">Topic分区初始化选择</a></li></ul></li><li><a href="#kafka-producer%E8%A7%A3%E6%9E%90">kafka producer解析</a><ul><li><a href="#1-%E5%8F%91%E9%80%81%E6%B5%81%E7%A8%8B">1. 发送流程</a></li><li><a href="#2-%E5%88%86%E5%8C%BA%E9%80%89%E6%8B%A9%E7%AD%96%E7%95%A5">2. 分区选择策略？</a></li><li><a href="#3-%E6%8B%A6%E6%88%AA%E5%99%A8%E6%9C%89%E4%BB%80%E4%B9%88%E4%BD%9C%E7%94%A8">3. 拦截器有什么作用？</a></li><li><a href="#4-%E5%85%B3%E9%94%AE%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84">4. 关键数据结构</a></li><li><a href="#5--%E5%8F%82%E6%95%B0%E9%85%8D%E7%BD%AE">5.  参数配置</a></li><li><a href="#6-ack%E6%9C%BA%E5%88%B6">6. ACK机制</a></li><li><a href="#7-producer%E4%B8%80%E4%BA%9B%E9%97%AE%E9%A2%98">7.一些问题</a></li></ul></li><li><a href="#kafka%E7%BD%91%E7%BB%9C%E6%8E%A5%E6%94%B6%E5%B1%82">Kafka网络接收层</a><ul><li><a href="#kafka-channel">Kafka channel</a></li><li><a href="#%E5%A6%82%E4%BD%95%E5%81%9A%E9%99%90%E6%B5%81%E7%9A%84">如何做限流的</a></li></ul></li><li><a href="#kafka%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86">Kafka内存管理</a><ul><li><a href="#%E5%A0%86%E5%86%85%E5%AD%98">堆内存</a></li><li><a href="#%E5%A0%86%E5%A4%96%E5%86%85%E5%AD%98">堆外内存</a></li></ul></li><li><a href="#kafka-%E5%AD%98%E5%82%A8%E5%B1%82%E8%A7%A3%E6%9E%90">kafka 存储层解析</a><ul><li><a href="#%E6%B6%88%E6%81%AF%E6%A0%BC%E5%BC%8F">消息格式</a></li><li><a href="#%E6%B6%88%E6%81%AF%E7%B4%A2%E5%BC%95">消息索引</a></li><li><a href="#%E4%B8%80%E4%BA%9B%E9%97%AE%E9%A2%98">一些问题</a></li></ul></li><li><a href="#%E5%89%AF%E6%9C%AC%E7%AE%A1%E7%90%86">副本管理</a><ul><li><a href="#failover%E6%9C%BA%E5%88%B6">failover机制</a></li></ul></li><li><a href="#kafka-consumer%E8%A7%A3%E6%9E%90">kafka Consumer解析</a><ul><li><a href="#082%E7%89%88%E6%9C%AC%E5%AE%A2%E6%88%B7%E7%AB%AF">0.8.2版本客户端</a></li><li><a href="#010%E7%89%88%E6%9C%AC%E5%AE%A2%E6%88%B7%E7%AB%AF">0.10版本客户端</a></li><li><a href="#%E4%B8%80%E4%BA%9B%E9%97%AE%E9%A2%98-1">一些问题</a></li></ul></li><li><a href="#zookeeper%E7%9A%84%E4%BD%9C%E7%94%A8">zookeeper的作用</a><ul><li><a href="#zookeeper%E5%9C%A8kafka%E4%B8%AD%E7%9A%84%E4%BD%9C%E7%94%A8">zookeeper在kafka中的作用</a></li></ul></li></ul></li></ul><h1 id="Kafka-端到端源码解析"><a href="#Kafka-端到端源码解析" class="headerlink" title="Kafka 端到端源码解析"></a>Kafka 端到端源码解析</h1><h2 id="Kafka的场景"><a href="#Kafka的场景" class="headerlink" title="Kafka的场景"></a>Kafka的场景</h2><h2 id="Kafka概念"><a href="#Kafka概念" class="headerlink" title="Kafka概念"></a>Kafka概念</h2><ul><li><strong>Broker</strong></li><li><strong>Topic</strong></li><li><strong>Partition</strong>   逻辑上最小的单元</li><li><strong>Offset</strong></li><li><strong>LogSegment</strong>   文件存储最小的单元</li><li><strong>Producer</strong>   生产者</li><li><strong>Consumer</strong>   消费者</li><li><strong>Zookeeper</strong>  提供分布式协调服务</li><li><strong>Controller</strong>   集群中的master</li><li><strong>ISR(In-Sync-Replica)</strong>   Topic分区的副本状态</li><li><strong>脑裂</strong> 集群中出现了双主，对于kafka来说是双controller</li><li><strong>羊群效应</strong> 当zookeeper上一个znode节点发生变化时，所有监听该节点的客户端都会发生相应的动作</li></ul><h2 id="Topic-创建与删除"><a href="#Topic-创建与删除" class="headerlink" title="Topic 创建与删除"></a>Topic 创建与删除</h2><p>   zk注册，controller选举具体的数据结构与流程</p><h3 id="Topic状态流转"><a href="#Topic状态流转" class="headerlink" title="Topic状态流转"></a>Topic状态流转</h3><p>   创建、在线、增加分区、下线、删除</p><h3 id="Topic-一些问题"><a href="#Topic-一些问题" class="headerlink" title="Topic 一些问题"></a>Topic 一些问题</h3><ul><li>topic分区数可不可以减少？如果可以，为什么？<br><br><strong>不可以</strong></li><li>Kafka 目前有哪些内部topic？分别的作用是什么？<br><br><strong>__consumer_offset</strong> 用来保存用户groupId对应的消费topic offset</li></ul><h3 id="Topic分区初始化选择"><a href="#Topic分区初始化选择" class="headerlink" title="Topic分区初始化选择"></a>Topic分区初始化选择</h3><p>  按照broker数量均匀地分布在每个broker上</p><h2 id="Kafka-Producer解析"><a href="#Kafka-Producer解析" class="headerlink" title="Kafka Producer解析"></a>Kafka Producer解析</h2><h3 id="1-发送流程"><a href="#1-发送流程" class="headerlink" title="1. 发送流程"></a>1. 发送流程</h3><ul><li>第一步： 刷新元数据</li><li>第二步： 序列化、选择分区、注册拦截器回调函数</li><li>第三步： 往RecordAccmulator发送数据</li><li>第四步：判断batch是否满了，满了的话唤醒send后台线程 <br><br><strong>有可能的异常：API版本不匹配；Buffer耗尽等</strong></li><li>第五步 ： send后台线程退出时，扫尾工作</li></ul><h3 id="2-分区选择策略？"><a href="#2-分区选择策略？" class="headerlink" title="2. 分区选择策略？"></a>2. 分区选择策略？</h3><ul><li>若该消息内无指定分区，则使用消息中指定的key哈希生成的分区</li><li>若key为null，则按照轮询的方式生成分区</li><li>最后一种，若仍然不满足需求，用户还可以自己指定partition分区策略类，每条消息都按照这个策略进行  <br><br>因此，分区策略可以有四个级别：用户自定义分区策略类、key哈希、轮询、任一消息选择任一分区，总的来说给用户很大的自由度。</li></ul><h3 id="3-拦截器有什么作用？"><a href="#3-拦截器有什么作用？" class="headerlink" title="3. 拦截器有什么作用？"></a>3. 拦截器有什么作用？</h3><p>在每次消息处理成功后增加一个回调函数，一般用来记录一些统计信息，为每条消息增加其他字段等等。</p><h3 id="4-关键数据结构"><a href="#4-关键数据结构" class="headerlink" title="4. 关键数据结构"></a>4. 关键数据结构</h3><p>RecordAccmulator数据结构的作用</p><p>的内部是如何运作的？这是个线程安全的数据结构</p><p>ConcurrentHashMap《TopicPartition，Batch队列》</p><p>Batch队列需要保证线程安全</p><p>有一个缓冲池bufferPool，每次开始是已经有batch在发，如果不存在则开辟batchSize大小的空间；然后往Batch队列的append数据，并且使得offset+1,然后会生成一个FutureRecordMetadata，用来表示batch是否满</p><p><strong>消息在如何在客户端存储的</strong>   <br><br>MemoryRecord 定义了一条消息在内存中的存储，</p><p>传输到socketChannel</p><h3 id="5-参数配置"><a href="#5-参数配置" class="headerlink" title="5.  参数配置"></a>5.  参数配置</h3><ol><li>batch.size指的是大小，不是消息数</li><li>ling.ms是每隔该时间就定时发送</li><li>maxFlightPerConnection&#x3D;1保证了消息在单分区内的顺序性</li></ol><h3 id="6-ACK机制"><a href="#6-ACK机制" class="headerlink" title="6. ACK机制"></a>6. ACK机制</h3><p> 代表对于消息可靠性的容忍度 <br><br> Ack&#x3D;1 代表leader返回ack即可 Ack&#x3D;-1 代表所有副本返回ack Ack&#x3D;0代表不需要返回</p><h3 id="7-Producer一些问题"><a href="#7-Producer一些问题" class="headerlink" title="7. Producer一些问题"></a>7. Producer一些问题</h3><ul><li>kafka 分区器、序列化器、拦截器之间的处理顺序？<br><br><strong>序列化器、分区器、 拦截器</strong>（发送完成后才会调用）</li><li>如何保证topic消息顺序性？<br><br><strong>全局消息顺序性</strong>：采用一个topic partition<br><strong>单分区顺序性</strong>：  maxFlightPerConnection&#x3D;1</li><li>性能调优问题？</li><li>数据压缩问题？</li><li>数据幂等性？<br><br>kafka 0.11版本之后提供了producer的幂等性</li><li>kafka 生产者客户端用了几个线程 <br><br> sender线程、producer主线程、</li></ul><h2 id="Kafka网络接收层"><a href="#Kafka网络接收层" class="headerlink" title="Kafka网络接收层"></a>Kafka网络接收层</h2><h3 id="Kafka-channel"><a href="#Kafka-channel" class="headerlink" title="Kafka channel"></a>Kafka channel</h3><h3 id="如何做限流的？"><a href="#如何做限流的？" class="headerlink" title="如何做限流的？"></a>如何做限流的？</h3><p>图中展示了通用的限流算法<br><img src="/throught_controller.png" alt="avatar"></p><p>server&#x2F;ClientQuatoManager负责进行流量控制</p><h3 id="如何做数据安全的？"><a href="#如何做数据安全的？" class="headerlink" title="如何做数据安全的？"></a>如何做数据安全的？</h3><h4 id="PageCache、mmap、zero-copy在kafka中的场景分别是什么？"><a href="#PageCache、mmap、zero-copy在kafka中的场景分别是什么？" class="headerlink" title="PageCache、mmap、zero-copy在kafka中的场景分别是什么？"></a>PageCache、mmap、zero-copy在kafka中的场景分别是什么？</h4><p>PageCache是文件缓存，属于操作系统层面的优化 –这个一般用来数据的缓存</p><p>mmap是内存映射文件 【MappedByteBuffer】用于index文件的读写</p><p>zero-copy是指在sendfile函数，可以直接从操作系统的文件中转移到网络channel 中，不需要走内核中转。在java中是fileChannel的trasferTo函数</p><p>那么这几个在kafka中，分别使用的是什么函数？ </p><p>ByteBuffer 堆内、、DirectByteBuffer</p><p>文件读写相关接口：FileChannel</p><p>zero-copy相关接口：sendFile();</p><h2 id="Kafka内存管理"><a href="#Kafka内存管理" class="headerlink" title="Kafka内存管理"></a>Kafka内存管理</h2><h3 id="堆外内存"><a href="#堆外内存" class="headerlink" title="堆外内存"></a>堆外内存</h3><p>堆外内存主要用在kafka consumer中，一般为了提高I&#x2F;O效率，都采用NIO的方式读取文件，而读取后的数据都保存在ByteBuffer数据结构中，ByteBuffer封装了堆外内存的引用。<br>ByteBufferMessageSet 解读</p><h2 id="kafka-存储层解析"><a href="#kafka-存储层解析" class="headerlink" title="kafka 存储层解析"></a>kafka 存储层解析</h2><p>存储层是利用本地文件系统的文件来存储的，首先每个topic对应N个分区，每个分区对应有三类文件（log文件、index文件与timeindex文件）。Log文件以每条二进制序列化后的消息为基本单位存储消息，每条消息的基本格式如下表格，而log文件分为很多个logsegment，每个segment的大小是一样的，例如1GB，三个文件的名字为文件中第一个消息的offset数值。</p><h3 id="消息格式-V1版本"><a href="#消息格式-V1版本" class="headerlink" title="消息格式(V1版本)"></a>消息格式(V1版本)</h3><table><thead><tr><th>filed</th><th>size</th><th>desciption</th></tr></thead><tbody><tr><td>offset</td><td>8 B</td><td>偏移量</td></tr><tr><td>message size</td><td>4 B</td><td>消息大小</td></tr><tr><td>crc32</td><td>4 B</td><td>crc校验码</td></tr><tr><td>magic</td><td>1B</td><td>Api的版本</td></tr><tr><td>timestamp</td><td>8 B</td><td>消息时间戳</td></tr><tr><td>attributes</td><td>1 B</td><td>属性？</td></tr><tr><td>key length</td><td>4 B</td><td>key的长度</td></tr><tr><td>key</td><td></td><td>key的消息体</td></tr><tr><td>value length</td><td>4B</td><td>value长度</td></tr><tr><td>value</td><td></td><td>消息体长度</td></tr></tbody></table><h3 id="消息索引"><a href="#消息索引" class="headerlink" title="消息索引"></a>消息索引</h3><ol><li><strong>给定时间戳—&gt;定位某个LogSegment—&gt;定位offset—&gt;定位消息位置?</strong> <br><br>根据时间戳查找offset，先顺序定位到LogSegment（找到第一个大于该时间戳的LogSegment),然后timeindex内部二分查找定位到offset</li><li><strong>给定offset—&gt; 定位到某个LogSegment—&gt;定位消息位置 ?</strong> <br><br> 根据offset，跳表中定位到LogSegment,然后index内部二分查找定位到offset位置，再顺序搜索定位到文件位置</li></ol><h3 id="刷盘策略"><a href="#刷盘策略" class="headerlink" title="刷盘策略"></a>刷盘策略</h3><p>kafka是异步刷盘的，有后台线程专程将内存中的数据写入到磁盘中<br>index 文件通过mmap从磁盘映射到用户空间内存中，log文件则是普通的读取文件。</p><h3 id="日志清理与Compaction"><a href="#日志清理与Compaction" class="headerlink" title="日志清理与Compaction"></a>日志清理与Compaction</h3><h3 id="流程与数据结构"><a href="#流程与数据结构" class="headerlink" title="流程与数据结构"></a>流程与数据结构</h3><h3 id="一些问题"><a href="#一些问题" class="headerlink" title="一些问题"></a>一些问题</h3><ul><li>谈谈你对页缓存、内核层、块层、设备层的理解  <br><br>内核层 ：操作系统中的内存数据与用户态buffer进行相互拷贝<br><br>pagecache : 文件读到操作系统内存中，操作系统的内存管理系统会预读 <br><br>块层：管理设备I&#x2F;O队列，对I&#x2F;O请求进行合并、排序等<br>设备层：通过DMA与内存直接交互，将数据写到磁盘</li></ul><h2 id="副本管理"><a href="#副本管理" class="headerlink" title="副本管理"></a>副本管理</h2><p>为什么用ISR，不用Raft之类的协议？借鉴了PacificA算法协议。 两个重要的组件：配置管理（对应kafka ISR，leader epoch commited_point) <br><br>&#x3D;&#x3D;HighWaterMark的作用：commited 消息度量；读可见性&#x3D;&#x3D;<br><a href="http://www.thinkingyu.com/articles/PacificA/">参考</a></p><h3 id="Failover机制"><a href="#Failover机制" class="headerlink" title="Failover机制"></a>Failover机制</h3><ul><li>若unclean.leader.election.enable为true，再去replica中去找存活的broker。而ISR中的broker存在是这样：只有当follower从leader拉取数据跟得上leader的数据速度时，才会在ISR中，否则，被剔除掉ISR列表中。</li><li>若unclean.leader.election.enable为false，抛出异常</li></ul><p>为什么会有unclean.leader.election.enable这个参数呢？</p><p>那么数据一致性是如何保证的呢，如何知道副本的状态是可靠的？ISR就保存了kafka认为可靠的副本，它们具备这样的条件：1 . 落后leader的消息条数在一定阈值内 2.或者落后在一定时间内；<br>但是，follower的复制状态谁又能保证一定能跟得上leader呢？这样，就存在着一种可能性，有可能ISR中只有leader,其他的副本都跟不上leader; 因此，这个时候，patition到底可用不可用？这就是一个权衡了，若只从ISR中获取leader，保证了数据的可靠性，但partition就不可用了，若从replica中获取，则可用性增强，但是数据可能存在丢失情况。<br>因此unclean.leader.election.enable这个参数设计为true，则保证了可用性，也就是CAP中的A P;设置为false，则保证了数据一致性，也就是CAP中的CP</p><h2 id="kafka-Consumer解析"><a href="#kafka-Consumer解析" class="headerlink" title="kafka Consumer解析"></a>kafka Consumer解析</h2><h3 id="推拉模型"><a href="#推拉模型" class="headerlink" title="推拉模型"></a>推拉模型</h3><p>推<br>拉</p><h3 id="0-8-2版本客户端"><a href="#0-8-2版本客户端" class="headerlink" title="0.8.2版本客户端"></a>0.8.2版本客户端</h3><h3 id="0-10版本客户端"><a href="#0-10版本客户端" class="headerlink" title="0.10版本客户端"></a>0.10版本客户端</h3><h3 id="一些问题-1"><a href="#一些问题-1" class="headerlink" title="一些问题"></a>一些问题</h3><ul><li>kafka 如何做到不重复消费? <br><br>现有的kafka可以做到写幂等性（0.11版本之后），但是做不到消费幂等性。消费完后写offset到zk失败，这个状态consumer客户端是感知不到的，二者并没有类似TCP的ack机制。因此下一次还是会从上次提交的offset继续读，就会出现重复消费。我个人觉得解决这个问题可以从两个方向来考虑：应用端做消费幂等性处理，也即每条消息会有一个全局的key，应用端保存消费过消息的key，每次新消费一条数据，key做重复判断，若重复，则丢弃这条数据。当然这会带来额外的内存与查询开销。<br><br>  同样，应用端也就是consumer端需要消息处理和offset提交这两步是事务的，也即要么操作成功要么撤回恢复之前的状态。这需要应用端有事务保障，但往往很多应用端是不支持事务的，比如kafka数据落盘hdfs，kafka数据消费完写入本地文件等等。但官方给的kafka consumer-process-kafka 给出了一个不错的参考的例子和思路。基本上遵循了分布式系统中的两阶段提交想法和思路，<a href="http://matt33.com/2018/11/04/kafka-transaction/">具体可以参见</a></li></ul><p>个人理解重复消费出现的概率并不会很高，在服务端改进会带来很大的性能损耗，这可能是为什么大家都选择不处理的重要原因吧。另外，本身系统与系统之间传输数据，很难做到消息的exactly once的。无论是kafka到存储系统hdfs还是spark flink下游计算系统等。若数据传输都在一个系统之内，那相对好处理一些，比如kafka的事务，保证了consume-process-producer的事务场景，也就是从kafka消费处理完毕后再到kafka，这个可以做到exactly once。</p><h2 id="zookeeper的作用"><a href="#zookeeper的作用" class="headerlink" title="zookeeper的作用"></a>zookeeper的作用</h2><h3 id="zookeeper在kafka中的作用"><a href="#zookeeper在kafka中的作用" class="headerlink" title="zookeeper在kafka中的作用"></a>zookeeper在kafka中的作用</h3><ol><li><strong>controller选举</strong>，所有的broker在zk &#x2F;controller下注册临时节点，任意一个抢先的broker注册成功，则为controller</li><li><strong>kafka consumer负载均衡</strong></li><li><strong>集群节点存活状态监测</strong></li><li><strong>topic创建触发</strong></li><li><strong>broker上线、下线的通知</strong></li><li><strong>ISR配置变更</strong></li></ol>]]></content>
    
    
    
    <tags>
      
      <tag>中间件,消息队列</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>开放平台技术</title>
    <link href="/2023/05/07/%E5%BC%80%E6%94%BE%E5%B9%B3%E5%8F%B0%E6%8A%80%E6%9C%AF/"/>
    <url>/2023/05/07/%E5%BC%80%E6%94%BE%E5%B9%B3%E5%8F%B0%E6%8A%80%E6%9C%AF/</url>
    
    <content type="html"><![CDATA[<h3 id="授权："><a href="#授权：" class="headerlink" title="授权："></a>授权：</h3><p>​    在淘宝开放平台上，授权是一种控制访问权限的机制。当开发者希望访问淘宝平台的用户数据或使用某些功能时，他们需要先向淘宝开放平台申请授权。用户可以根据自己的需求选择授权给特定的应用程序或服务，以便控制对自己个人信息的访问和使用。</p><p>​    授权通常涉及用户的身份验证和权限管理。开发者需要通过OAuth等认证协议来验证用户的身份，并获得用户的授权许可。用户可以选择授予应用程序特定的权限，例如读取商品信息、下单、发表评价等。用户在授权过程中可以查看应用程序请求的权限范围，并可以随时取消或更改授权。</p><h3 id="网关"><a href="#网关" class="headerlink" title="网关"></a>网关</h3><p>签名算法、微服务</p><h4 id="高性能技术："><a href="#高性能技术：" class="headerlink" title="高性能技术："></a>高性能技术：</h4><p>异步化：</p><p>多级缓存：</p><p>流控：</p><h3 id="消息"><a href="#消息" class="headerlink" title="消息"></a>消息</h3><h3 id="SPI"><a href="#SPI" class="headerlink" title="SPI"></a>SPI</h3><p>服务端提供</p><h3 id="SDK"><a href="#SDK" class="headerlink" title="SDK"></a>SDK</h3><p>SDK生成技术</p>]]></content>
    
    
    
  </entry>
  
  
  
  
</search>
