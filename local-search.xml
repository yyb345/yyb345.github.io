<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>LLMAgent学习笔记</title>
    <link href="/2024/01/07/LLMAgent%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    <url>/2024/01/07/LLMAgent%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/</url>
    
    <content type="html"><![CDATA[<p>上文介绍了LangChain的基本原理，但是越来越发现Agent的重要性</p><h1 id="Agent基本概念"><a href="#Agent基本概念" class="headerlink" title="Agent基本概念"></a>Agent基本概念</h1><p>Planning</p><p>Thinking</p><p>Action</p><p>Memory</p><h1 id="多Agent-Framework"><a href="#多Agent-Framework" class="headerlink" title="多Agent Framework"></a>多Agent Framework</h1><p>MetaGPT</p><img src="https://docs.deepwisdom.ai/main/image/guide/tutorials/multi_agents_flowchart.png" alt="img" style="zoom: 33%;" /><p>核心的元素：观察、提示词+工具、返回结果集成到上下文中。</p>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>自动化测试</title>
    <link href="/2023/12/23/%E8%87%AA%E5%8A%A8%E5%8C%96%E6%B5%8B%E8%AF%95/"/>
    <url>/2023/12/23/%E8%87%AA%E5%8A%A8%E5%8C%96%E6%B5%8B%E8%AF%95/</url>
    
    <content type="html"><![CDATA[<h3 id="流量采集"><a href="#流量采集" class="headerlink" title="流量采集"></a>流量采集</h3><p>关键技术：采样率</p><h3 id="测试用例管理"><a href="#测试用例管理" class="headerlink" title="测试用例管理"></a>测试用例管理</h3><h3 id="用例重放-amp-测试报告"><a href="#用例重放-amp-测试报告" class="headerlink" title="用例重放&amp;测试报告"></a>用例重放&amp;测试报告</h3><p>断言、返回结果数据分析</p>]]></content>
    
    
    
    <tags>
      
      <tag>自动化</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>LangChain原理解析</title>
    <link href="/2023/12/20/langchain/"/>
    <url>/2023/12/20/langchain/</url>
    
    <content type="html"><![CDATA[<p>最新越发觉得AI的发展，对未来是一场革命，LangChain已经在工程设计上有了最佳实践，类似于AI时代的编程模型或编程框架，有点Spring框架的意思。之前在LangChain上也有些最佳实践，所以在这里分享记录下。</p><h3 id="LangChain属于哪一层"><a href="#LangChain属于哪一层" class="headerlink" title="LangChain属于哪一层"></a>LangChain属于哪一层</h3><p>​    LangChain是基于LLM之上的，在应用层和底层LLM之前的一个很好的编程框架，如果把LLM比喻为各种类型的数据库、中间件等这些基础设施，应用层是各种业务逻辑的组合之外，那么LangChain就负责桥接与业务层和底层LLM模型，让开发者可以快速地实现对接各种底层模型和快速实现业务逻辑的软件开发框架。</p><p>   那么LangChain是如何做到的呢？试想一下，现在底层有一个大模型的推理能力，除了在对话框手动输入跟他聊天之外。如何用计算机方式跟它互动呢？如果把一次LLM调用当作一个原子能力，如何编排这些原子能力来解决一些业务需求呢？Langchain就是来解决这个事情的。</p><h3 id="LangChain的几个核心概念"><a href="#LangChain的几个核心概念" class="headerlink" title="LangChain的几个核心概念"></a>LangChain的几个核心概念</h3><h4 id="格式化数据（I-x2F-O）"><a href="#格式化数据（I-x2F-O）" class="headerlink" title="格式化数据（I&#x2F;O）"></a>格式化数据（I&#x2F;O）</h4><h4 id="Retriver"><a href="#Retriver" class="headerlink" title="Retriver"></a>Retriver</h4><p>   检索是为了解决大模型打通用户的本身数据，做一些面向业务属性的东西。这里的检索并非传统的关系型数据库，更多的是与大模型的本身逻辑相似的，比如向量数据库。</p><h5 id="一个经典的结合LLM和外部用户的文档进行智能答疑的场景"><a href="#一个经典的结合LLM和外部用户的文档进行智能答疑的场景" class="headerlink" title="一个经典的结合LLM和外部用户的文档进行智能答疑的场景"></a>一个经典的结合LLM和外部用户的文档进行智能答疑的场景</h5><p>文档-&gt;分词-&gt;embedding-&gt;向量数据库</p><p>query-&gt;向量数据库查询-&gt;TOP N-&gt;上下文+ 用户提问 + prompt -&gt; LLM -&gt; 返回结果</p><p>一个经典的图如下：</p><img src="/images/langchain_chatglm.png" alt="img" style="zoom:20%;" /><p><strong>关键技术：文档如何拆分、embedding过程、 TOPN 向量距离的选择</strong></p><p>embedding技术选型</p><p> embedding是将现实中的物体通过向量化的方法转化为高维向量，可被机器学习模型所识别。他是一种映射，同时也保证了能清晰地表达现实物体的特征。基于此，可以进行一些归类分析、回归分析等。</p><p>现在市面上常见的embedding方法有通义千问的embedding等方法。</p><p>向量数据库</p><p>​     向量数据库底层存储的是一堆向量，它提供了根据向量相似度进行查询的能力，一般情况下，向量相似度代表了现实世界中物体的相似度。比如”我的名字是小明“ 和“我叫小明”这两句话所代表的含义几乎是相同的，那么在embedding之后，基于向量数据库进行查询的时候，它们俩的相似度就会很近。</p><p>现在市面上常见的向量数据库有xxx</p><h4 id="Chain"><a href="#Chain" class="headerlink" title="Chain"></a>Chain</h4><p>各种类型的chain，chain代表了各种业务类型的组合，类似于工作流的编排。</p><h4 id="Memory"><a href="#Memory" class="headerlink" title="Memory"></a>Memory</h4><p>LLM本身提供了记忆的能力，同时提供了接口，开发者可以将历史的对话记录传入给LLM。LangChain需要使用外部存储保存这些历史的会话和记忆。可以使用数据库、缓存等进行保存。</p><h4 id="Agent"><a href="#Agent" class="headerlink" title="Agent"></a>Agent</h4><h5 id="重点是代理工具"><a href="#重点是代理工具" class="headerlink" title="重点是代理工具"></a>重点是代理工具</h5><p>   代理工具可以让应用程序基于大模型的推理能力，然后进行代理工具或代理服务的调用。因为LLM是没有“联网”的能力的，如果想解决特定的应用场景，代理工具是个完美的选择。</p><p>代理工具通常包含三个方面： 用户输入、prompt编排LLM思考与路由代理的过程、背后的代理服务。其中难点可能就在于prompt设计了。通常的“套路”是这样的：</p><h5 id="ReAct-模型："><a href="#ReAct-模型：" class="headerlink" title="ReAct 模型："></a>ReAct 模型：</h5><p>输入：用户的问题</p><p>思考过程：如果是情况1（这个是需要LLM进行意图识别进行思考的），那么推理和提取出一些关键参数，调用agent1，如果是情况2，那么推理和提取出一些关键参数，调用agent2</p><p>Act：调用agent1对应一个JSON格式化的输入，调用function1，返回结果。</p><p>观察：观察调用后的结果，再结合推理的能力，再进行循环思考。</p><h3 id="LangChain的在实际场景中的实践"><a href="#LangChain的在实际场景中的实践" class="headerlink" title="LangChain的在实际场景中的实践"></a>LangChain的在实际场景中的实践</h3><h4 id="智能问答"><a href="#智能问答" class="headerlink" title="智能问答"></a>智能问答</h4><p>Embedding 是将FAQ的知识库</p><p>prompt+embedding+ 向量数据库+agent </p><h4 id=""><a href="#" class="headerlink" title=""></a></h4>]]></content>
    
    
    
    <tags>
      
      <tag>AI,LangChain,LLM</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>kafka脑裂问题</title>
    <link href="/2023/12/20/kafka%E8%84%91%E8%A3%82%E9%97%AE%E9%A2%98/"/>
    <url>/2023/12/20/kafka%E8%84%91%E8%A3%82%E9%97%AE%E9%A2%98/</url>
    
    <content type="html"><![CDATA[<h2 id="什么是脑裂？"><a href="#什么是脑裂？" class="headerlink" title="什么是脑裂？"></a>什么是脑裂？</h2><p>​     脑裂是分布式系统高可用（High Avaliablity）场景下容易出现的问题。我们知道，在分布式系统中常常用多副本来解决容错性问题，多副本中会选举出一个Leader负责与客户端进行交互，但由于各种原因分布式集群中会出现脑裂的情况</p><p>zookeeper脑裂问题 - tantexian的博客空间 - OSCHINAmy.oschina.net&#x2F;tantexian&#x2F;blog&#x2F;2876309</p><p> 这篇文章给出了详细的解释。这里再简单概述以下，基本上是由于网络或者其他原因导致master出现假死，这时候会触发系统进行新的master选举，此时系统中就会出现两个master，产生一系列问题。</p><h2 id="什么是kafka-controller？"><a href="#什么是kafka-controller？" class="headerlink" title="什么是kafka controller？"></a>什么是kafka controller？</h2><p>​    kafka controller相当于整个kafka集群的<strong>master</strong>，负责topic的创建、删除、以及partition的状态机转换，broker的上线、下线等。那么controller是如何选举出来的呢？它是通过抢占方式在zookeeper上注册临时节点来实现的，第一个注册成功的即为controller。关键之处来了，由于<strong>zookeeper临时节点的有效性是通过session来判断的，若在session timeout时间内，controller所在的broker断掉，则会触发新的controller选举。</strong></p><h2 id="kafka-Controller脑裂带来什么问题？"><a href="#kafka-Controller脑裂带来什么问题？" class="headerlink" title="kafka Controller脑裂带来什么问题？"></a>kafka Controller脑裂带来什么问题？</h2><p>什么服务会受到影响？Topic元数据信息新增或者改变时，会在对应的zookeeper path下添加或者更新数据，而controller都对这个路径进行了watch，当有数据变化时，controller会进行partition、replica state的转化，进而对所有存活的broker发送LeaderISR请求，这时第二个controller会发生错误，进而元数据更新失败，对应的partition无法变为online状态。</p><ol><li>创建新的topic成功，客户端往topic内写数据时； </li><li>给某个topic增加分区，zk显示已有增加的分区信息，但是依旧报找不到新增加的分区信息错误</li></ol><p>什么服务不会受到影响？</p><p>  现有的topic读写不受影响，因为读写时获取partition的元数据信息在任意broker上都可以获取到</p><h2 id="什么情况下会导致这个问题？如何解决？"><a href="#什么情况下会导致这个问题？如何解决？" class="headerlink" title="什么情况下会导致这个问题？如何解决？"></a>什么情况下会导致这个问题？如何解决？</h2><ol><li>Controller进行Full GC停顿时间太长超过zookeeper session timeout 出现假死</li><li>Controller 所在broker网络出现故障</li></ol><p>解决方案1：在zk上找到最新的controller所在的broker， 将其余几个过期的controller重启，找其余controller办法，通过上图jmx指标获取value&#x3D;1的 broker</p><p><img src="https://picx.zhimg.com/80/v2-071a5a1f9984922f258d09c589c40ad0_1440w.png?source=d16d100b" alt="img"></p><p>添加图片注释，不超过 140 字（可选）</p><p>解决方案2:</p><p>升级新版本，新版本解决了这个BUG</p>]]></content>
    
    
    
    <tags>
      
      <tag>稳定性</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>hexo</title>
    <link href="/2023/12/20/hexo/"/>
    <url>/2023/12/20/hexo/</url>
    
    <content type="html"><![CDATA[<p>Hexo 是一个基于 Node.js 的静态博客框架，允许你使用 Markdown 编写文章，然后通过 Hexo 生成静态网页。以下是一些常用的 Hexo 命令：</p><p>初始化博客：</p><p>bash<br>Copy code<br>hexo init <folder><br>cd <folder><br>用于在指定文件夹中初始化一个 Hexo 博客。</p><p>生成静态文件：</p><p>bash<br>Copy code<br>hexo generate<br>用于将 Markdown 文件转换为静态 HTML 文件。</p><p>启动本地服务器：</p><p>bash<br>Copy code<br>hexo server<br>用于启动一个本地服务器，可以在浏览器中预览生成的静态网页。默认地址是 <a href="http://localhost:4000。">http://localhost:4000。</a></p><p>新建文章：</p><p>bash<br>Copy code<br>hexo new [layout] <title><br>用于新建一篇文章。可选的 layout 参数可以是 post（默认）、page 等。</p><p>部署到远程仓库（如GitHub）：</p><p>bash<br>Copy code<br>hexo deploy<br>用于将生成的静态文件部署到配置好的远程仓库。</p><p>清理缓存文件：</p><p>bash<br>Copy code<br>hexo clean<br>用于清理 Hexo 生成过程中产生的临时文件。</p><p>查看帮助：</p><p>bash<br>Copy code<br>hexo –help<br>用于查看 Hexo 的帮助信息，包括可用命令和选项。</p><p>这些是一些基本的 Hexo 命令，你可以根据需要进一步了解 Hexo 的配置和插件系统以及其他更高级的用法。</p>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>低代码中的关键技术</title>
    <link href="/2023/06/11/%E4%BD%8E%E4%BB%A3%E7%A0%81%E4%B8%AD%E7%9A%84%E5%85%B3%E9%94%AE%E6%8A%80%E6%9C%AF/"/>
    <url>/2023/06/11/%E4%BD%8E%E4%BB%A3%E7%A0%81%E4%B8%AD%E7%9A%84%E5%85%B3%E9%94%AE%E6%8A%80%E6%9C%AF/</url>
    
    <content type="html"><![CDATA[<p>低代码在某些场景下的开发效率会很高，比如xxx。因此有必要研究一下低代码场景下的一些核心功能。</p><h2 id="页面"><a href="#页面" class="headerlink" title="页面"></a>页面</h2><p>表单搭建</p><ol><li>Google Forms：<ul><li>优点：简单易用，免费使用，与Google账号和Google Drive无缝集成，可轻松创建各种类型的表单，支持多种问题类型和自定义选项。</li><li>缺点：功能相对较基础，定制性较低，对于复杂的表单需求可能不够满足。</li></ul></li><li>Microsoft Forms：<ul><li>优点：集成于Microsoft Office 365，支持与Microsoft Teams、SharePoint等工具无缝协作，具备丰富的表单设计和逻辑控制功能，易于创建和分享表单。</li><li>缺点：功能相对较简化，仅限于Microsoft Office 365生态系统。</li></ul></li><li>JotForm：<ul><li>优点：提供丰富的表单模板和设计工具，具备强大的表单逻辑和自动化功能，支持在线支付和集成多种第三方应用程序。</li><li>缺点：高级功能需要付费订阅，某些特定功能可能需要额外的配置和集成。</li></ul></li><li>Wufoo：<ul><li>优点：用户友好的界面，提供多种预设计表单模板，支持自定义设计和布局，具备强大的报告和分析功能。</li><li>缺点：部分高级功能需要付费订阅，集成和扩展性相对有限。</li></ul></li><li>Typeform：<ul><li>优点：独特的用户体验，通过交互式设计和动态问答形式创建表单，支持多媒体内容和自定义主题，提供强大的数据分析和可视化功能。</li><li>缺点：某些高级功能和定制选项需要付费订阅，特殊设计可能需要一定的学习曲线。</li></ul></li></ol><h2 id="工作流"><a href="#工作流" class="headerlink" title="工作流"></a>工作流</h2><h3 id="工作流引擎"><a href="#工作流引擎" class="headerlink" title="工作流引擎"></a>工作流引擎</h3><ol><li><p>Apache Airflow: 优点：</p><ul><li>支持可扩展的任务调度和工作流编排，具有高度灵活性。</li><li>提供可视化的用户界面和丰富的插件生态系统。</li><li>具备良好的可编程性和可定制性，适用于复杂的工作流需求。</li></ul><p>缺点：</p><ul><li>部署和配置较为复杂，对于初学者来说有一定的学习曲线。</li><li>可视化界面相对简单，不够直观。</li></ul></li><li><p>Camunda BPM: 优点：</p><ul><li>提供全面的业务流程管理解决方案，具有强大的工作流引擎功能。</li><li>支持复杂的流程编排和规则引擎。</li><li>提供了用户友好的建模工具和监控面板。</li></ul><p>缺点：</p><ul><li>需要一定的开发技能和理解业务流程建模的概念。</li><li>需要额外的配置和集成才能适应特定的环境和需求。</li></ul></li><li><p>IBM Business Automation Workflow: 优点：</p><ul><li>提供完整的工作流和决策管理解决方案，包括流程建模、执行和监控。</li><li>支持高度可扩展的分布式架构和大规模部署。</li><li>具备强大的决策规则引擎和自动化决策能力。</li></ul><p>缺点：</p><ul><li>高度定制化和企业级功能可能会导致复杂性增加。</li><li>相对较高的成本和学习曲线，适用于大型企业和复杂业务场景。</li></ul></li><li><p>Microsoft Power Automate (以前的Microsoft Flow): 优点：</p><ul><li>与Microsoft Office 365和其他Microsoft产品集成紧密，易于使用和配置。</li><li>提供丰富的连接器和模板，便于快速构建常见的工作流程。</li><li>可以通过低代码方式进行自定义扩展。</li></ul><p>缺点：</p><ul><li>功能相对较简化，不适用于复杂的工作流需求。</li><li>集成主要面向Microsoft生态系统，对其他系统和平台的支持有限。</li></ul></li></ol><table><thead><tr><th align="left">工作流引擎</th><th>优点</th><th>缺点</th></tr></thead><tbody><tr><td align="left">Smart-engine</td><td></td><td></td></tr><tr><td align="left"></td><td></td><td></td></tr><tr><td align="left"></td><td></td><td></td></tr></tbody></table><h3 id="工作流搭建"><a href="#工作流搭建" class="headerlink" title="工作流搭建"></a>工作流搭建</h3><h3 id="事件中心"><a href="#事件中心" class="headerlink" title="事件中心"></a>事件中心</h3><p>事件中心一般包括 消息出发、HTTP触发等方式。</p><h3 id="连接器"><a href="#连接器" class="headerlink" title="连接器"></a>连接器</h3><p>连接器一般用来连接工作流和微服务的调用。核心功能有代理执行和参数映射</p><h2 id="工作表"><a href="#工作表" class="headerlink" title="工作表"></a>工作表</h2><p>用来进行用户数据存储。用户数据存储可以用传统的Mysql，也可以用分布式数据库XXX。</p><p>EXCEL导入是一个比较常见的功能，Easy-Excel是一个不错的框架。</p><h3 id="数据空间"><a href="#数据空间" class="headerlink" title="数据空间"></a>数据空间</h3>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>Kafka原理</title>
    <link href="/2023/05/07/Kafka%E5%8E%9F%E7%90%86/"/>
    <url>/2023/05/07/Kafka%E5%8E%9F%E7%90%86/</url>
    
    <content type="html"><![CDATA[<ul><li><a href="#kafka-%E7%AB%AF%E5%88%B0%E7%AB%AF%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90">Kafka 端到端源码解析</a><ul><li><a href="#kafka%E7%9A%84%E5%9C%BA%E6%99%AF">Kafka的场景</a></li><li><a href="#kafka%E6%A6%82%E5%BF%B5">Kafka概念</a></li><li><a href="#topic-%E5%88%9B%E5%BB%BA%E4%B8%8E%E5%88%A0%E9%99%A4">Topic 创建与删除</a><ul><li><a href="#topic%E7%8A%B6%E6%80%81%E6%B5%81%E8%BD%AC">Topic状态流转</a></li><li><a href="#topic-%E4%B8%80%E4%BA%9B%E9%97%AE%E9%A2%98">一些问题</a></li><li><a href="#topic%E5%88%86%E5%8C%BA%E5%88%9D%E5%A7%8B%E5%8C%96%E9%80%89%E6%8B%A9">Topic分区初始化选择</a></li></ul></li><li><a href="#kafka-producer%E8%A7%A3%E6%9E%90">kafka producer解析</a><ul><li><a href="#1-%E5%8F%91%E9%80%81%E6%B5%81%E7%A8%8B">1. 发送流程</a></li><li><a href="#2-%E5%88%86%E5%8C%BA%E9%80%89%E6%8B%A9%E7%AD%96%E7%95%A5">2. 分区选择策略？</a></li><li><a href="#3-%E6%8B%A6%E6%88%AA%E5%99%A8%E6%9C%89%E4%BB%80%E4%B9%88%E4%BD%9C%E7%94%A8">3. 拦截器有什么作用？</a></li><li><a href="#4-%E5%85%B3%E9%94%AE%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84">4. 关键数据结构</a></li><li><a href="#5--%E5%8F%82%E6%95%B0%E9%85%8D%E7%BD%AE">5.  参数配置</a></li><li><a href="#6-ack%E6%9C%BA%E5%88%B6">6. ACK机制</a></li><li><a href="#7-producer%E4%B8%80%E4%BA%9B%E9%97%AE%E9%A2%98">7.一些问题</a></li></ul></li><li><a href="#kafka%E7%BD%91%E7%BB%9C%E6%8E%A5%E6%94%B6%E5%B1%82">Kafka网络接收层</a><ul><li><a href="#kafka-channel">Kafka channel</a></li><li><a href="#%E5%A6%82%E4%BD%95%E5%81%9A%E9%99%90%E6%B5%81%E7%9A%84">如何做限流的</a></li></ul></li><li><a href="#kafka%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86">Kafka内存管理</a><ul><li><a href="#%E5%A0%86%E5%86%85%E5%AD%98">堆内存</a></li><li><a href="#%E5%A0%86%E5%A4%96%E5%86%85%E5%AD%98">堆外内存</a></li></ul></li><li><a href="#kafka-%E5%AD%98%E5%82%A8%E5%B1%82%E8%A7%A3%E6%9E%90">kafka 存储层解析</a><ul><li><a href="#%E6%B6%88%E6%81%AF%E6%A0%BC%E5%BC%8F">消息格式</a></li><li><a href="#%E6%B6%88%E6%81%AF%E7%B4%A2%E5%BC%95">消息索引</a></li><li><a href="#%E4%B8%80%E4%BA%9B%E9%97%AE%E9%A2%98">一些问题</a></li></ul></li><li><a href="#%E5%89%AF%E6%9C%AC%E7%AE%A1%E7%90%86">副本管理</a><ul><li><a href="#failover%E6%9C%BA%E5%88%B6">failover机制</a></li></ul></li><li><a href="#kafka-consumer%E8%A7%A3%E6%9E%90">kafka Consumer解析</a><ul><li><a href="#082%E7%89%88%E6%9C%AC%E5%AE%A2%E6%88%B7%E7%AB%AF">0.8.2版本客户端</a></li><li><a href="#010%E7%89%88%E6%9C%AC%E5%AE%A2%E6%88%B7%E7%AB%AF">0.10版本客户端</a></li><li><a href="#%E4%B8%80%E4%BA%9B%E9%97%AE%E9%A2%98-1">一些问题</a></li></ul></li><li><a href="#zookeeper%E7%9A%84%E4%BD%9C%E7%94%A8">zookeeper的作用</a><ul><li><a href="#zookeeper%E5%9C%A8kafka%E4%B8%AD%E7%9A%84%E4%BD%9C%E7%94%A8">zookeeper在kafka中的作用</a></li></ul></li></ul></li></ul><h1 id="Kafka-端到端源码解析"><a href="#Kafka-端到端源码解析" class="headerlink" title="Kafka 端到端源码解析"></a>Kafka 端到端源码解析</h1><h2 id="Kafka的场景"><a href="#Kafka的场景" class="headerlink" title="Kafka的场景"></a>Kafka的场景</h2><h2 id="Kafka概念"><a href="#Kafka概念" class="headerlink" title="Kafka概念"></a>Kafka概念</h2><ul><li><strong>Broker</strong></li><li><strong>Topic</strong></li><li><strong>Partition</strong>   逻辑上最小的单元</li><li><strong>Offset</strong></li><li><strong>LogSegment</strong>   文件存储最小的单元</li><li><strong>Producer</strong>   生产者</li><li><strong>Consumer</strong>   消费者</li><li><strong>Zookeeper</strong>  提供分布式协调服务</li><li><strong>Controller</strong>   集群中的master</li><li><strong>ISR(In-Sync-Replica)</strong>   Topic分区的副本状态</li><li><strong>脑裂</strong> 集群中出现了双主，对于kafka来说是双controller</li><li><strong>羊群效应</strong> 当zookeeper上一个znode节点发生变化时，所有监听该节点的客户端都会发生相应的动作</li></ul><h2 id="Topic-创建与删除"><a href="#Topic-创建与删除" class="headerlink" title="Topic 创建与删除"></a>Topic 创建与删除</h2><p>   zk注册，controller选举具体的数据结构与流程</p><h3 id="Topic状态流转"><a href="#Topic状态流转" class="headerlink" title="Topic状态流转"></a>Topic状态流转</h3><p>   创建、在线、增加分区、下线、删除</p><h3 id="Topic-一些问题"><a href="#Topic-一些问题" class="headerlink" title="Topic 一些问题"></a>Topic 一些问题</h3><ul><li>topic分区数可不可以减少？如果可以，为什么？<br><br><strong>不可以</strong></li><li>Kafka 目前有哪些内部topic？分别的作用是什么？<br><br><strong>__consumer_offset</strong> 用来保存用户groupId对应的消费topic offset</li></ul><h3 id="Topic分区初始化选择"><a href="#Topic分区初始化选择" class="headerlink" title="Topic分区初始化选择"></a>Topic分区初始化选择</h3><p>  按照broker数量均匀地分布在每个broker上</p><h2 id="Kafka-Producer解析"><a href="#Kafka-Producer解析" class="headerlink" title="Kafka Producer解析"></a>Kafka Producer解析</h2><h3 id="1-发送流程"><a href="#1-发送流程" class="headerlink" title="1. 发送流程"></a>1. 发送流程</h3><ul><li>第一步： 刷新元数据</li><li>第二步： 序列化、选择分区、注册拦截器回调函数</li><li>第三步： 往RecordAccmulator发送数据</li><li>第四步：判断batch是否满了，满了的话唤醒send后台线程 <br><br><strong>有可能的异常：API版本不匹配；Buffer耗尽等</strong></li><li>第五步 ： send后台线程退出时，扫尾工作</li></ul><h3 id="2-分区选择策略？"><a href="#2-分区选择策略？" class="headerlink" title="2. 分区选择策略？"></a>2. 分区选择策略？</h3><ul><li>若该消息内无指定分区，则使用消息中指定的key哈希生成的分区</li><li>若key为null，则按照轮询的方式生成分区</li><li>最后一种，若仍然不满足需求，用户还可以自己指定partition分区策略类，每条消息都按照这个策略进行  <br><br>因此，分区策略可以有四个级别：用户自定义分区策略类、key哈希、轮询、任一消息选择任一分区，总的来说给用户很大的自由度。</li></ul><h3 id="3-拦截器有什么作用？"><a href="#3-拦截器有什么作用？" class="headerlink" title="3. 拦截器有什么作用？"></a>3. 拦截器有什么作用？</h3><p>在每次消息处理成功后增加一个回调函数，一般用来记录一些统计信息，为每条消息增加其他字段等等。</p><h3 id="4-关键数据结构"><a href="#4-关键数据结构" class="headerlink" title="4. 关键数据结构"></a>4. 关键数据结构</h3><p>RecordAccmulator数据结构的作用</p><p>的内部是如何运作的？这是个线程安全的数据结构</p><p>ConcurrentHashMap《TopicPartition，Batch队列》</p><p>Batch队列需要保证线程安全</p><p>有一个缓冲池bufferPool，每次开始是已经有batch在发，如果不存在则开辟batchSize大小的空间；然后往Batch队列的append数据，并且使得offset+1,然后会生成一个FutureRecordMetadata，用来表示batch是否满</p><p><strong>消息在如何在客户端存储的</strong>   <br><br>MemoryRecord 定义了一条消息在内存中的存储，</p><p>传输到socketChannel</p><h3 id="5-参数配置"><a href="#5-参数配置" class="headerlink" title="5.  参数配置"></a>5.  参数配置</h3><ol><li>batch.size指的是大小，不是消息数</li><li>ling.ms是每隔该时间就定时发送</li><li>maxFlightPerConnection&#x3D;1保证了消息在单分区内的顺序性</li></ol><h3 id="6-ACK机制"><a href="#6-ACK机制" class="headerlink" title="6. ACK机制"></a>6. ACK机制</h3><p> 代表对于消息可靠性的容忍度 <br><br> Ack&#x3D;1 代表leader返回ack即可 Ack&#x3D;-1 代表所有副本返回ack Ack&#x3D;0代表不需要返回</p><h3 id="7-Producer一些问题"><a href="#7-Producer一些问题" class="headerlink" title="7. Producer一些问题"></a>7. Producer一些问题</h3><ul><li>kafka 分区器、序列化器、拦截器之间的处理顺序？<br><br><strong>序列化器、分区器、 拦截器</strong>（发送完成后才会调用）</li><li>如何保证topic消息顺序性？<br><br><strong>全局消息顺序性</strong>：采用一个topic partition<br><strong>单分区顺序性</strong>：  maxFlightPerConnection&#x3D;1</li><li>性能调优问题？</li><li>数据压缩问题？</li><li>数据幂等性？<br><br>kafka 0.11版本之后提供了producer的幂等性</li><li>kafka 生产者客户端用了几个线程 <br><br> sender线程、producer主线程、</li></ul><h2 id="Kafka网络接收层"><a href="#Kafka网络接收层" class="headerlink" title="Kafka网络接收层"></a>Kafka网络接收层</h2><h3 id="Kafka-channel"><a href="#Kafka-channel" class="headerlink" title="Kafka channel"></a>Kafka channel</h3><h3 id="如何做限流的？"><a href="#如何做限流的？" class="headerlink" title="如何做限流的？"></a>如何做限流的？</h3><p>图中展示了通用的限流算法<br><img src="/throught_controller.png" alt="avatar"></p><p>server&#x2F;ClientQuatoManager负责进行流量控制</p><h3 id="如何做数据安全的？"><a href="#如何做数据安全的？" class="headerlink" title="如何做数据安全的？"></a>如何做数据安全的？</h3><h4 id="PageCache、mmap、zero-copy在kafka中的场景分别是什么？"><a href="#PageCache、mmap、zero-copy在kafka中的场景分别是什么？" class="headerlink" title="PageCache、mmap、zero-copy在kafka中的场景分别是什么？"></a>PageCache、mmap、zero-copy在kafka中的场景分别是什么？</h4><p>PageCache是文件缓存，属于操作系统层面的优化 –这个一般用来数据的缓存</p><p>mmap是内存映射文件 【MappedByteBuffer】用于index文件的读写</p><p>zero-copy是指在sendfile函数，可以直接从操作系统的文件中转移到网络channel 中，不需要走内核中转。在java中是fileChannel的trasferTo函数</p><p>那么这几个在kafka中，分别使用的是什么函数？ </p><p>ByteBuffer 堆内、、DirectByteBuffer</p><p>文件读写相关接口：FileChannel</p><p>zero-copy相关接口：sendFile();</p><h2 id="Kafka内存管理"><a href="#Kafka内存管理" class="headerlink" title="Kafka内存管理"></a>Kafka内存管理</h2><h3 id="堆外内存"><a href="#堆外内存" class="headerlink" title="堆外内存"></a>堆外内存</h3><p>堆外内存主要用在kafka consumer中，一般为了提高I&#x2F;O效率，都采用NIO的方式读取文件，而读取后的数据都保存在ByteBuffer数据结构中，ByteBuffer封装了堆外内存的引用。<br>ByteBufferMessageSet 解读</p><h2 id="kafka-存储层解析"><a href="#kafka-存储层解析" class="headerlink" title="kafka 存储层解析"></a>kafka 存储层解析</h2><p>存储层是利用本地文件系统的文件来存储的，首先每个topic对应N个分区，每个分区对应有三类文件（log文件、index文件与timeindex文件）。Log文件以每条二进制序列化后的消息为基本单位存储消息，每条消息的基本格式如下表格，而log文件分为很多个logsegment，每个segment的大小是一样的，例如1GB，三个文件的名字为文件中第一个消息的offset数值。</p><h3 id="消息格式-V1版本"><a href="#消息格式-V1版本" class="headerlink" title="消息格式(V1版本)"></a>消息格式(V1版本)</h3><table><thead><tr><th>filed</th><th>size</th><th>desciption</th></tr></thead><tbody><tr><td>offset</td><td>8 B</td><td>偏移量</td></tr><tr><td>message size</td><td>4 B</td><td>消息大小</td></tr><tr><td>crc32</td><td>4 B</td><td>crc校验码</td></tr><tr><td>magic</td><td>1B</td><td>Api的版本</td></tr><tr><td>timestamp</td><td>8 B</td><td>消息时间戳</td></tr><tr><td>attributes</td><td>1 B</td><td>属性？</td></tr><tr><td>key length</td><td>4 B</td><td>key的长度</td></tr><tr><td>key</td><td></td><td>key的消息体</td></tr><tr><td>value length</td><td>4B</td><td>value长度</td></tr><tr><td>value</td><td></td><td>消息体长度</td></tr></tbody></table><h3 id="消息索引"><a href="#消息索引" class="headerlink" title="消息索引"></a>消息索引</h3><ol><li><strong>给定时间戳—&gt;定位某个LogSegment—&gt;定位offset—&gt;定位消息位置?</strong> <br><br>根据时间戳查找offset，先顺序定位到LogSegment（找到第一个大于该时间戳的LogSegment),然后timeindex内部二分查找定位到offset</li><li><strong>给定offset—&gt; 定位到某个LogSegment—&gt;定位消息位置 ?</strong> <br><br> 根据offset，跳表中定位到LogSegment,然后index内部二分查找定位到offset位置，再顺序搜索定位到文件位置</li></ol><h3 id="刷盘策略"><a href="#刷盘策略" class="headerlink" title="刷盘策略"></a>刷盘策略</h3><p>kafka是异步刷盘的，有后台线程专程将内存中的数据写入到磁盘中<br>index 文件通过mmap从磁盘映射到用户空间内存中，log文件则是普通的读取文件。</p><h3 id="日志清理与Compaction"><a href="#日志清理与Compaction" class="headerlink" title="日志清理与Compaction"></a>日志清理与Compaction</h3><h3 id="流程与数据结构"><a href="#流程与数据结构" class="headerlink" title="流程与数据结构"></a>流程与数据结构</h3><h3 id="一些问题"><a href="#一些问题" class="headerlink" title="一些问题"></a>一些问题</h3><ul><li>谈谈你对页缓存、内核层、块层、设备层的理解  <br><br>内核层 ：操作系统中的内存数据与用户态buffer进行相互拷贝<br><br>pagecache : 文件读到操作系统内存中，操作系统的内存管理系统会预读 <br><br>块层：管理设备I&#x2F;O队列，对I&#x2F;O请求进行合并、排序等<br>设备层：通过DMA与内存直接交互，将数据写到磁盘</li></ul><h2 id="副本管理"><a href="#副本管理" class="headerlink" title="副本管理"></a>副本管理</h2><p>为什么用ISR，不用Raft之类的协议？借鉴了PacificA算法协议。 两个重要的组件：配置管理（对应kafka ISR，leader epoch commited_point) <br><br>&#x3D;&#x3D;HighWaterMark的作用：commited 消息度量；读可见性&#x3D;&#x3D;<br><a href="http://www.thinkingyu.com/articles/PacificA/">参考</a></p><h3 id="Failover机制"><a href="#Failover机制" class="headerlink" title="Failover机制"></a>Failover机制</h3><ul><li>若unclean.leader.election.enable为true，再去replica中去找存活的broker。而ISR中的broker存在是这样：只有当follower从leader拉取数据跟得上leader的数据速度时，才会在ISR中，否则，被剔除掉ISR列表中。</li><li>若unclean.leader.election.enable为false，抛出异常</li></ul><p>为什么会有unclean.leader.election.enable这个参数呢？</p><p>那么数据一致性是如何保证的呢，如何知道副本的状态是可靠的？ISR就保存了kafka认为可靠的副本，它们具备这样的条件：1 . 落后leader的消息条数在一定阈值内 2.或者落后在一定时间内；<br>但是，follower的复制状态谁又能保证一定能跟得上leader呢？这样，就存在着一种可能性，有可能ISR中只有leader,其他的副本都跟不上leader; 因此，这个时候，patition到底可用不可用？这就是一个权衡了，若只从ISR中获取leader，保证了数据的可靠性，但partition就不可用了，若从replica中获取，则可用性增强，但是数据可能存在丢失情况。<br>因此unclean.leader.election.enable这个参数设计为true，则保证了可用性，也就是CAP中的A P;设置为false，则保证了数据一致性，也就是CAP中的CP</p><h2 id="kafka-Consumer解析"><a href="#kafka-Consumer解析" class="headerlink" title="kafka Consumer解析"></a>kafka Consumer解析</h2><h3 id="推拉模型"><a href="#推拉模型" class="headerlink" title="推拉模型"></a>推拉模型</h3><p>推<br>拉</p><h3 id="0-8-2版本客户端"><a href="#0-8-2版本客户端" class="headerlink" title="0.8.2版本客户端"></a>0.8.2版本客户端</h3><h3 id="0-10版本客户端"><a href="#0-10版本客户端" class="headerlink" title="0.10版本客户端"></a>0.10版本客户端</h3><h3 id="一些问题-1"><a href="#一些问题-1" class="headerlink" title="一些问题"></a>一些问题</h3><ul><li>kafka 如何做到不重复消费? <br><br>现有的kafka可以做到写幂等性（0.11版本之后），但是做不到消费幂等性。消费完后写offset到zk失败，这个状态consumer客户端是感知不到的，二者并没有类似TCP的ack机制。因此下一次还是会从上次提交的offset继续读，就会出现重复消费。我个人觉得解决这个问题可以从两个方向来考虑：应用端做消费幂等性处理，也即每条消息会有一个全局的key，应用端保存消费过消息的key，每次新消费一条数据，key做重复判断，若重复，则丢弃这条数据。当然这会带来额外的内存与查询开销。<br><br>  同样，应用端也就是consumer端需要消息处理和offset提交这两步是事务的，也即要么操作成功要么撤回恢复之前的状态。这需要应用端有事务保障，但往往很多应用端是不支持事务的，比如kafka数据落盘hdfs，kafka数据消费完写入本地文件等等。但官方给的kafka consumer-process-kafka 给出了一个不错的参考的例子和思路。基本上遵循了分布式系统中的两阶段提交想法和思路，<a href="http://matt33.com/2018/11/04/kafka-transaction/">具体可以参见</a></li></ul><p>个人理解重复消费出现的概率并不会很高，在服务端改进会带来很大的性能损耗，这可能是为什么大家都选择不处理的重要原因吧。另外，本身系统与系统之间传输数据，很难做到消息的exactly once的。无论是kafka到存储系统hdfs还是spark flink下游计算系统等。若数据传输都在一个系统之内，那相对好处理一些，比如kafka的事务，保证了consume-process-producer的事务场景，也就是从kafka消费处理完毕后再到kafka，这个可以做到exactly once。</p><h2 id="zookeeper的作用"><a href="#zookeeper的作用" class="headerlink" title="zookeeper的作用"></a>zookeeper的作用</h2><h3 id="zookeeper在kafka中的作用"><a href="#zookeeper在kafka中的作用" class="headerlink" title="zookeeper在kafka中的作用"></a>zookeeper在kafka中的作用</h3><ol><li><strong>controller选举</strong>，所有的broker在zk &#x2F;controller下注册临时节点，任意一个抢先的broker注册成功，则为controller</li><li><strong>kafka consumer负载均衡</strong></li><li><strong>集群节点存活状态监测</strong></li><li><strong>topic创建触发</strong></li><li><strong>broker上线、下线的通知</strong></li><li><strong>ISR配置变更</strong></li></ol>]]></content>
    
    
    
    <tags>
      
      <tag>中间件,消息队列</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>开放平台相关</title>
    <link href="/2023/05/07/%E7%AC%AC%E4%B8%80%E7%AF%87%E6%96%87%E7%AB%A0/"/>
    <url>/2023/05/07/%E7%AC%AC%E4%B8%80%E7%AF%87%E6%96%87%E7%AB%A0/</url>
    
    <content type="html"><![CDATA[<p>ISV身份：</p><p>应用：</p><h3 id="授权："><a href="#授权：" class="headerlink" title="授权："></a>授权：</h3><p>​    在淘宝开放平台上，授权是一种控制访问权限的机制。当开发者希望访问淘宝平台的用户数据或使用某些功能时，他们需要先向淘宝开放平台申请授权。用户可以根据自己的需求选择授权给特定的应用程序或服务，以便控制对自己个人信息的访问和使用。</p><p>​    授权通常涉及用户的身份验证和权限管理。开发者需要通过OAuth等认证协议来验证用户的身份，并获得用户的授权许可。用户可以选择授予应用程序特定的权限，例如读取商品信息、下单、发表评价等。用户在授权过程中可以查看应用程序请求的权限范围，并可以随时取消或更改授权。</p><p>API</p><p>消息</p><p>SPI</p><p>SDK</p><p>错误码</p><h3 id="网关："><a href="#网关：" class="headerlink" title="网关："></a>网关：</h3>]]></content>
    
    
    
  </entry>
  
  
  
  
</search>
