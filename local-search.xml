<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>低代码中的关键技术</title>
    <link href="/2023/06/11/%E4%BD%8E%E4%BB%A3%E7%A0%81%E4%B8%AD%E7%9A%84%E5%85%B3%E9%94%AE%E6%8A%80%E6%9C%AF/"/>
    <url>/2023/06/11/%E4%BD%8E%E4%BB%A3%E7%A0%81%E4%B8%AD%E7%9A%84%E5%85%B3%E9%94%AE%E6%8A%80%E6%9C%AF/</url>
    
    <content type="html"><![CDATA[<p>低代码在某些场景下的开发效率会很高，比如xxx。因此有必要研究一下低代码场景下的一些核心功能。</p><h2 id="页面"><a href="#页面" class="headerlink" title="页面"></a>页面</h2><p>表单搭建</p><ol><li>Google Forms：<ul><li>优点：简单易用，免费使用，与Google账号和Google Drive无缝集成，可轻松创建各种类型的表单，支持多种问题类型和自定义选项。</li><li>缺点：功能相对较基础，定制性较低，对于复杂的表单需求可能不够满足。</li></ul></li><li>Microsoft Forms：<ul><li>优点：集成于Microsoft Office 365，支持与Microsoft Teams、SharePoint等工具无缝协作，具备丰富的表单设计和逻辑控制功能，易于创建和分享表单。</li><li>缺点：功能相对较简化，仅限于Microsoft Office 365生态系统。</li></ul></li><li>JotForm：<ul><li>优点：提供丰富的表单模板和设计工具，具备强大的表单逻辑和自动化功能，支持在线支付和集成多种第三方应用程序。</li><li>缺点：高级功能需要付费订阅，某些特定功能可能需要额外的配置和集成。</li></ul></li><li>Wufoo：<ul><li>优点：用户友好的界面，提供多种预设计表单模板，支持自定义设计和布局，具备强大的报告和分析功能。</li><li>缺点：部分高级功能需要付费订阅，集成和扩展性相对有限。</li></ul></li><li>Typeform：<ul><li>优点：独特的用户体验，通过交互式设计和动态问答形式创建表单，支持多媒体内容和自定义主题，提供强大的数据分析和可视化功能。</li><li>缺点：某些高级功能和定制选项需要付费订阅，特殊设计可能需要一定的学习曲线。</li></ul></li></ol><h2 id="工作流"><a href="#工作流" class="headerlink" title="工作流"></a>工作流</h2><h3 id="工作流引擎"><a href="#工作流引擎" class="headerlink" title="工作流引擎"></a>工作流引擎</h3><ol><li><p>Apache Airflow: 优点：</p><ul><li>支持可扩展的任务调度和工作流编排，具有高度灵活性。</li><li>提供可视化的用户界面和丰富的插件生态系统。</li><li>具备良好的可编程性和可定制性，适用于复杂的工作流需求。</li></ul><p>缺点：</p><ul><li>部署和配置较为复杂，对于初学者来说有一定的学习曲线。</li><li>可视化界面相对简单，不够直观。</li></ul></li><li><p>Camunda BPM: 优点：</p><ul><li>提供全面的业务流程管理解决方案，具有强大的工作流引擎功能。</li><li>支持复杂的流程编排和规则引擎。</li><li>提供了用户友好的建模工具和监控面板。</li></ul><p>缺点：</p><ul><li>需要一定的开发技能和理解业务流程建模的概念。</li><li>需要额外的配置和集成才能适应特定的环境和需求。</li></ul></li><li><p>IBM Business Automation Workflow: 优点：</p><ul><li>提供完整的工作流和决策管理解决方案，包括流程建模、执行和监控。</li><li>支持高度可扩展的分布式架构和大规模部署。</li><li>具备强大的决策规则引擎和自动化决策能力。</li></ul><p>缺点：</p><ul><li>高度定制化和企业级功能可能会导致复杂性增加。</li><li>相对较高的成本和学习曲线，适用于大型企业和复杂业务场景。</li></ul></li><li><p>Microsoft Power Automate (以前的Microsoft Flow): 优点：</p><ul><li>与Microsoft Office 365和其他Microsoft产品集成紧密，易于使用和配置。</li><li>提供丰富的连接器和模板，便于快速构建常见的工作流程。</li><li>可以通过低代码方式进行自定义扩展。</li></ul><p>缺点：</p><ul><li>功能相对较简化，不适用于复杂的工作流需求。</li><li>集成主要面向Microsoft生态系统，对其他系统和平台的支持有限。</li></ul></li></ol><table><thead><tr><th align="left">工作流引擎</th><th>优点</th><th>缺点</th></tr></thead><tbody><tr><td align="left">Smart-engine</td><td></td><td></td></tr><tr><td align="left"></td><td></td><td></td></tr><tr><td align="left"></td><td></td><td></td></tr></tbody></table><h3 id="工作流搭建"><a href="#工作流搭建" class="headerlink" title="工作流搭建"></a>工作流搭建</h3><h3 id="事件中心"><a href="#事件中心" class="headerlink" title="事件中心"></a>事件中心</h3><p>事件中心一般包括 消息出发、HTTP触发等方式。</p><h3 id="连接器"><a href="#连接器" class="headerlink" title="连接器"></a>连接器</h3><p>连接器一般用来连接工作流和微服务的调用。核心功能有代理执行和参数映射</p><h2 id="工作表"><a href="#工作表" class="headerlink" title="工作表"></a>工作表</h2><p>用来进行用户数据存储。用户数据存储可以用传统的Mysql，也可以用分布式数据库XXX。</p><p>EXCEL导入是一个比较常见的功能，Easy-Excel是一个不错的框架。</p><h3 id="数据空间"><a href="#数据空间" class="headerlink" title="数据空间"></a>数据空间</h3>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>Kafka原理</title>
    <link href="/2023/05/07/Kafka%E5%8E%9F%E7%90%86/"/>
    <url>/2023/05/07/Kafka%E5%8E%9F%E7%90%86/</url>
    
    <content type="html"><![CDATA[<ul><li><a href="#kafka-%E7%AB%AF%E5%88%B0%E7%AB%AF%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90">Kafka 端到端源码解析</a><ul><li><a href="#kafka%E7%9A%84%E5%9C%BA%E6%99%AF">Kafka的场景</a></li><li><a href="#kafka%E6%A6%82%E5%BF%B5">Kafka概念</a></li><li><a href="#topic-%E5%88%9B%E5%BB%BA%E4%B8%8E%E5%88%A0%E9%99%A4">Topic 创建与删除</a><ul><li><a href="#topic%E7%8A%B6%E6%80%81%E6%B5%81%E8%BD%AC">Topic状态流转</a></li><li><a href="#topic-%E4%B8%80%E4%BA%9B%E9%97%AE%E9%A2%98">一些问题</a></li><li><a href="#topic%E5%88%86%E5%8C%BA%E5%88%9D%E5%A7%8B%E5%8C%96%E9%80%89%E6%8B%A9">Topic分区初始化选择</a></li></ul></li><li><a href="#kafka-producer%E8%A7%A3%E6%9E%90">kafka producer解析</a><ul><li><a href="#1-%E5%8F%91%E9%80%81%E6%B5%81%E7%A8%8B">1. 发送流程</a></li><li><a href="#2-%E5%88%86%E5%8C%BA%E9%80%89%E6%8B%A9%E7%AD%96%E7%95%A5">2. 分区选择策略？</a></li><li><a href="#3-%E6%8B%A6%E6%88%AA%E5%99%A8%E6%9C%89%E4%BB%80%E4%B9%88%E4%BD%9C%E7%94%A8">3. 拦截器有什么作用？</a></li><li><a href="#4-%E5%85%B3%E9%94%AE%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84">4. 关键数据结构</a></li><li><a href="#5--%E5%8F%82%E6%95%B0%E9%85%8D%E7%BD%AE">5.  参数配置</a></li><li><a href="#6-ack%E6%9C%BA%E5%88%B6">6. ACK机制</a></li><li><a href="#7-producer%E4%B8%80%E4%BA%9B%E9%97%AE%E9%A2%98">7.一些问题</a></li></ul></li><li><a href="#kafka%E7%BD%91%E7%BB%9C%E6%8E%A5%E6%94%B6%E5%B1%82">Kafka网络接收层</a><ul><li><a href="#kafka-channel">Kafka channel</a></li><li><a href="#%E5%A6%82%E4%BD%95%E5%81%9A%E9%99%90%E6%B5%81%E7%9A%84">如何做限流的</a></li></ul></li><li><a href="#kafka%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86">Kafka内存管理</a><ul><li><a href="#%E5%A0%86%E5%86%85%E5%AD%98">堆内存</a></li><li><a href="#%E5%A0%86%E5%A4%96%E5%86%85%E5%AD%98">堆外内存</a></li></ul></li><li><a href="#kafka-%E5%AD%98%E5%82%A8%E5%B1%82%E8%A7%A3%E6%9E%90">kafka 存储层解析</a><ul><li><a href="#%E6%B6%88%E6%81%AF%E6%A0%BC%E5%BC%8F">消息格式</a></li><li><a href="#%E6%B6%88%E6%81%AF%E7%B4%A2%E5%BC%95">消息索引</a></li><li><a href="#%E4%B8%80%E4%BA%9B%E9%97%AE%E9%A2%98">一些问题</a></li></ul></li><li><a href="#%E5%89%AF%E6%9C%AC%E7%AE%A1%E7%90%86">副本管理</a><ul><li><a href="#failover%E6%9C%BA%E5%88%B6">failover机制</a></li></ul></li><li><a href="#kafka-consumer%E8%A7%A3%E6%9E%90">kafka Consumer解析</a><ul><li><a href="#082%E7%89%88%E6%9C%AC%E5%AE%A2%E6%88%B7%E7%AB%AF">0.8.2版本客户端</a></li><li><a href="#010%E7%89%88%E6%9C%AC%E5%AE%A2%E6%88%B7%E7%AB%AF">0.10版本客户端</a></li><li><a href="#%E4%B8%80%E4%BA%9B%E9%97%AE%E9%A2%98-1">一些问题</a></li></ul></li><li><a href="#zookeeper%E7%9A%84%E4%BD%9C%E7%94%A8">zookeeper的作用</a><ul><li><a href="#zookeeper%E5%9C%A8kafka%E4%B8%AD%E7%9A%84%E4%BD%9C%E7%94%A8">zookeeper在kafka中的作用</a></li></ul></li></ul></li></ul><h1 id="Kafka-端到端源码解析"><a href="#Kafka-端到端源码解析" class="headerlink" title="Kafka 端到端源码解析"></a>Kafka 端到端源码解析</h1><h2 id="Kafka的场景"><a href="#Kafka的场景" class="headerlink" title="Kafka的场景"></a>Kafka的场景</h2><h2 id="Kafka概念"><a href="#Kafka概念" class="headerlink" title="Kafka概念"></a>Kafka概念</h2><ul><li><strong>Broker</strong></li><li><strong>Topic</strong></li><li><strong>Partition</strong>   逻辑上最小的单元</li><li><strong>Offset</strong></li><li><strong>LogSegment</strong>   文件存储最小的单元</li><li><strong>Producer</strong>   生产者</li><li><strong>Consumer</strong>   消费者</li><li><strong>Zookeeper</strong>  提供分布式协调服务</li><li><strong>Controller</strong>   集群中的master</li><li><strong>ISR(In-Sync-Replica)</strong>   Topic分区的副本状态</li><li><strong>脑裂</strong> 集群中出现了双主，对于kafka来说是双controller</li><li><strong>羊群效应</strong> 当zookeeper上一个znode节点发生变化时，所有监听该节点的客户端都会发生相应的动作</li></ul><h2 id="Topic-创建与删除"><a href="#Topic-创建与删除" class="headerlink" title="Topic 创建与删除"></a>Topic 创建与删除</h2><p>   zk注册，controller选举具体的数据结构与流程</p><h3 id="Topic状态流转"><a href="#Topic状态流转" class="headerlink" title="Topic状态流转"></a>Topic状态流转</h3><p>   创建、在线、增加分区、下线、删除</p><h3 id="Topic-一些问题"><a href="#Topic-一些问题" class="headerlink" title="Topic 一些问题"></a>Topic 一些问题</h3><ul><li>topic分区数可不可以减少？如果可以，为什么？<br><br><strong>不可以</strong></li><li>Kafka 目前有哪些内部topic？分别的作用是什么？<br><br><strong>__consumer_offset</strong> 用来保存用户groupId对应的消费topic offset</li></ul><h3 id="Topic分区初始化选择"><a href="#Topic分区初始化选择" class="headerlink" title="Topic分区初始化选择"></a>Topic分区初始化选择</h3><p>  按照broker数量均匀地分布在每个broker上</p><h2 id="Kafka-Producer解析"><a href="#Kafka-Producer解析" class="headerlink" title="Kafka Producer解析"></a>Kafka Producer解析</h2><h3 id="1-发送流程"><a href="#1-发送流程" class="headerlink" title="1. 发送流程"></a>1. 发送流程</h3><ul><li>第一步： 刷新元数据</li><li>第二步： 序列化、选择分区、注册拦截器回调函数</li><li>第三步： 往RecordAccmulator发送数据</li><li>第四步：判断batch是否满了，满了的话唤醒send后台线程 <br><br><strong>有可能的异常：API版本不匹配；Buffer耗尽等</strong></li><li>第五步 ： send后台线程退出时，扫尾工作</li></ul><h3 id="2-分区选择策略？"><a href="#2-分区选择策略？" class="headerlink" title="2. 分区选择策略？"></a>2. 分区选择策略？</h3><ul><li>若该消息内无指定分区，则使用消息中指定的key哈希生成的分区</li><li>若key为null，则按照轮询的方式生成分区</li><li>最后一种，若仍然不满足需求，用户还可以自己指定partition分区策略类，每条消息都按照这个策略进行  <br><br>因此，分区策略可以有四个级别：用户自定义分区策略类、key哈希、轮询、任一消息选择任一分区，总的来说给用户很大的自由度。</li></ul><h3 id="3-拦截器有什么作用？"><a href="#3-拦截器有什么作用？" class="headerlink" title="3. 拦截器有什么作用？"></a>3. 拦截器有什么作用？</h3><p>在每次消息处理成功后增加一个回调函数，一般用来记录一些统计信息，为每条消息增加其他字段等等。</p><h3 id="4-关键数据结构"><a href="#4-关键数据结构" class="headerlink" title="4. 关键数据结构"></a>4. 关键数据结构</h3><p>RecordAccmulator数据结构的作用</p><p>的内部是如何运作的？这是个线程安全的数据结构</p><p>ConcurrentHashMap《TopicPartition，Batch队列》</p><p>Batch队列需要保证线程安全</p><p>有一个缓冲池bufferPool，每次开始是已经有batch在发，如果不存在则开辟batchSize大小的空间；然后往Batch队列的append数据，并且使得offset+1,然后会生成一个FutureRecordMetadata，用来表示batch是否满</p><p><strong>消息在如何在客户端存储的</strong>   <br><br>MemoryRecord 定义了一条消息在内存中的存储，</p><p>传输到socketChannel</p><h3 id="5-参数配置"><a href="#5-参数配置" class="headerlink" title="5.  参数配置"></a>5.  参数配置</h3><ol><li>batch.size指的是大小，不是消息数</li><li>ling.ms是每隔该时间就定时发送</li><li>maxFlightPerConnection&#x3D;1保证了消息在单分区内的顺序性</li></ol><h3 id="6-ACK机制"><a href="#6-ACK机制" class="headerlink" title="6. ACK机制"></a>6. ACK机制</h3><p> 代表对于消息可靠性的容忍度 <br><br> Ack&#x3D;1 代表leader返回ack即可 Ack&#x3D;-1 代表所有副本返回ack Ack&#x3D;0代表不需要返回</p><h3 id="7-Producer一些问题"><a href="#7-Producer一些问题" class="headerlink" title="7. Producer一些问题"></a>7. Producer一些问题</h3><ul><li>kafka 分区器、序列化器、拦截器之间的处理顺序？<br><br><strong>序列化器、分区器、 拦截器</strong>（发送完成后才会调用）</li><li>如何保证topic消息顺序性？<br><br><strong>全局消息顺序性</strong>：采用一个topic partition<br><strong>单分区顺序性</strong>：  maxFlightPerConnection&#x3D;1</li><li>性能调优问题？</li><li>数据压缩问题？</li><li>数据幂等性？<br><br>kafka 0.11版本之后提供了producer的幂等性</li><li>kafka 生产者客户端用了几个线程 <br><br> sender线程、producer主线程、</li></ul><h2 id="Kafka网络接收层"><a href="#Kafka网络接收层" class="headerlink" title="Kafka网络接收层"></a>Kafka网络接收层</h2><h3 id="Kafka-channel"><a href="#Kafka-channel" class="headerlink" title="Kafka channel"></a>Kafka channel</h3><h3 id="如何做限流的？"><a href="#如何做限流的？" class="headerlink" title="如何做限流的？"></a>如何做限流的？</h3><p>图中展示了通用的限流算法<br><img src="/throught_controller.png" alt="avatar"></p><p>server&#x2F;ClientQuatoManager负责进行流量控制</p><h3 id="如何做数据安全的？"><a href="#如何做数据安全的？" class="headerlink" title="如何做数据安全的？"></a>如何做数据安全的？</h3><h4 id="PageCache、mmap、zero-copy在kafka中的场景分别是什么？"><a href="#PageCache、mmap、zero-copy在kafka中的场景分别是什么？" class="headerlink" title="PageCache、mmap、zero-copy在kafka中的场景分别是什么？"></a>PageCache、mmap、zero-copy在kafka中的场景分别是什么？</h4><p>PageCache是文件缓存，属于操作系统层面的优化 –这个一般用来数据的缓存</p><p>mmap是内存映射文件 【MappedByteBuffer】用于index文件的读写</p><p>zero-copy是指在sendfile函数，可以直接从操作系统的文件中转移到网络channel 中，不需要走内核中转。在java中是fileChannel的trasferTo函数</p><p>那么这几个在kafka中，分别使用的是什么函数？ </p><p>ByteBuffer 堆内、、DirectByteBuffer</p><p>文件读写相关接口：FileChannel</p><p>zero-copy相关接口：sendFile();</p><h2 id="Kafka内存管理"><a href="#Kafka内存管理" class="headerlink" title="Kafka内存管理"></a>Kafka内存管理</h2><h3 id="堆外内存"><a href="#堆外内存" class="headerlink" title="堆外内存"></a>堆外内存</h3><p>堆外内存主要用在kafka consumer中，一般为了提高I&#x2F;O效率，都采用NIO的方式读取文件，而读取后的数据都保存在ByteBuffer数据结构中，ByteBuffer封装了堆外内存的引用。<br>ByteBufferMessageSet 解读</p><h2 id="kafka-存储层解析"><a href="#kafka-存储层解析" class="headerlink" title="kafka 存储层解析"></a>kafka 存储层解析</h2><p>存储层是利用本地文件系统的文件来存储的，首先每个topic对应N个分区，每个分区对应有三类文件（log文件、index文件与timeindex文件）。Log文件以每条二进制序列化后的消息为基本单位存储消息，每条消息的基本格式如下表格，而log文件分为很多个logsegment，每个segment的大小是一样的，例如1GB，三个文件的名字为文件中第一个消息的offset数值。</p><h3 id="消息格式-V1版本"><a href="#消息格式-V1版本" class="headerlink" title="消息格式(V1版本)"></a>消息格式(V1版本)</h3><table><thead><tr><th>filed</th><th>size</th><th>desciption</th></tr></thead><tbody><tr><td>offset</td><td>8 B</td><td>偏移量</td></tr><tr><td>message size</td><td>4 B</td><td>消息大小</td></tr><tr><td>crc32</td><td>4 B</td><td>crc校验码</td></tr><tr><td>magic</td><td>1B</td><td>Api的版本</td></tr><tr><td>timestamp</td><td>8 B</td><td>消息时间戳</td></tr><tr><td>attributes</td><td>1 B</td><td>属性？</td></tr><tr><td>key length</td><td>4 B</td><td>key的长度</td></tr><tr><td>key</td><td></td><td>key的消息体</td></tr><tr><td>value length</td><td>4B</td><td>value长度</td></tr><tr><td>value</td><td></td><td>消息体长度</td></tr></tbody></table><h3 id="消息索引"><a href="#消息索引" class="headerlink" title="消息索引"></a>消息索引</h3><ol><li><strong>给定时间戳—&gt;定位某个LogSegment—&gt;定位offset—&gt;定位消息位置?</strong> <br><br>根据时间戳查找offset，先顺序定位到LogSegment（找到第一个大于该时间戳的LogSegment),然后timeindex内部二分查找定位到offset</li><li><strong>给定offset—&gt; 定位到某个LogSegment—&gt;定位消息位置 ?</strong> <br><br> 根据offset，跳表中定位到LogSegment,然后index内部二分查找定位到offset位置，再顺序搜索定位到文件位置</li></ol><h3 id="刷盘策略"><a href="#刷盘策略" class="headerlink" title="刷盘策略"></a>刷盘策略</h3><p>kafka是异步刷盘的，有后台线程专程将内存中的数据写入到磁盘中<br>index 文件通过mmap从磁盘映射到用户空间内存中，log文件则是普通的读取文件。</p><h3 id="日志清理与Compaction"><a href="#日志清理与Compaction" class="headerlink" title="日志清理与Compaction"></a>日志清理与Compaction</h3><h3 id="流程与数据结构"><a href="#流程与数据结构" class="headerlink" title="流程与数据结构"></a>流程与数据结构</h3><h3 id="一些问题"><a href="#一些问题" class="headerlink" title="一些问题"></a>一些问题</h3><ul><li>谈谈你对页缓存、内核层、块层、设备层的理解  <br><br>内核层 ：操作系统中的内存数据与用户态buffer进行相互拷贝<br><br>pagecache : 文件读到操作系统内存中，操作系统的内存管理系统会预读 <br><br>块层：管理设备I&#x2F;O队列，对I&#x2F;O请求进行合并、排序等<br>设备层：通过DMA与内存直接交互，将数据写到磁盘</li></ul><h2 id="副本管理"><a href="#副本管理" class="headerlink" title="副本管理"></a>副本管理</h2><p>为什么用ISR，不用Raft之类的协议？借鉴了PacificA算法协议。 两个重要的组件：配置管理（对应kafka ISR，leader epoch commited_point) <br><br>&#x3D;&#x3D;HighWaterMark的作用：commited 消息度量；读可见性&#x3D;&#x3D;<br><a href="http://www.thinkingyu.com/articles/PacificA/">参考</a></p><h3 id="Failover机制"><a href="#Failover机制" class="headerlink" title="Failover机制"></a>Failover机制</h3><ul><li>若unclean.leader.election.enable为true，再去replica中去找存活的broker。而ISR中的broker存在是这样：只有当follower从leader拉取数据跟得上leader的数据速度时，才会在ISR中，否则，被剔除掉ISR列表中。</li><li>若unclean.leader.election.enable为false，抛出异常</li></ul><p>为什么会有unclean.leader.election.enable这个参数呢？</p><p>那么数据一致性是如何保证的呢，如何知道副本的状态是可靠的？ISR就保存了kafka认为可靠的副本，它们具备这样的条件：1 . 落后leader的消息条数在一定阈值内 2.或者落后在一定时间内；<br>但是，follower的复制状态谁又能保证一定能跟得上leader呢？这样，就存在着一种可能性，有可能ISR中只有leader,其他的副本都跟不上leader; 因此，这个时候，patition到底可用不可用？这就是一个权衡了，若只从ISR中获取leader，保证了数据的可靠性，但partition就不可用了，若从replica中获取，则可用性增强，但是数据可能存在丢失情况。<br>因此unclean.leader.election.enable这个参数设计为true，则保证了可用性，也就是CAP中的A P;设置为false，则保证了数据一致性，也就是CAP中的CP</p><h2 id="kafka-Consumer解析"><a href="#kafka-Consumer解析" class="headerlink" title="kafka Consumer解析"></a>kafka Consumer解析</h2><h3 id="推拉模型"><a href="#推拉模型" class="headerlink" title="推拉模型"></a>推拉模型</h3><p>推<br>拉</p><h3 id="0-8-2版本客户端"><a href="#0-8-2版本客户端" class="headerlink" title="0.8.2版本客户端"></a>0.8.2版本客户端</h3><h3 id="0-10版本客户端"><a href="#0-10版本客户端" class="headerlink" title="0.10版本客户端"></a>0.10版本客户端</h3><h3 id="一些问题-1"><a href="#一些问题-1" class="headerlink" title="一些问题"></a>一些问题</h3><ul><li>kafka 如何做到不重复消费? <br><br>现有的kafka可以做到写幂等性（0.11版本之后），但是做不到消费幂等性。消费完后写offset到zk失败，这个状态consumer客户端是感知不到的，二者并没有类似TCP的ack机制。因此下一次还是会从上次提交的offset继续读，就会出现重复消费。我个人觉得解决这个问题可以从两个方向来考虑：应用端做消费幂等性处理，也即每条消息会有一个全局的key，应用端保存消费过消息的key，每次新消费一条数据，key做重复判断，若重复，则丢弃这条数据。当然这会带来额外的内存与查询开销。<br><br>  同样，应用端也就是consumer端需要消息处理和offset提交这两步是事务的，也即要么操作成功要么撤回恢复之前的状态。这需要应用端有事务保障，但往往很多应用端是不支持事务的，比如kafka数据落盘hdfs，kafka数据消费完写入本地文件等等。但官方给的kafka consumer-process-kafka 给出了一个不错的参考的例子和思路。基本上遵循了分布式系统中的两阶段提交想法和思路，<a href="http://matt33.com/2018/11/04/kafka-transaction/">具体可以参见</a></li></ul><p>个人理解重复消费出现的概率并不会很高，在服务端改进会带来很大的性能损耗，这可能是为什么大家都选择不处理的重要原因吧。另外，本身系统与系统之间传输数据，很难做到消息的exactly once的。无论是kafka到存储系统hdfs还是spark flink下游计算系统等。若数据传输都在一个系统之内，那相对好处理一些，比如kafka的事务，保证了consume-process-producer的事务场景，也就是从kafka消费处理完毕后再到kafka，这个可以做到exactly once。</p><h2 id="zookeeper的作用"><a href="#zookeeper的作用" class="headerlink" title="zookeeper的作用"></a>zookeeper的作用</h2><h3 id="zookeeper在kafka中的作用"><a href="#zookeeper在kafka中的作用" class="headerlink" title="zookeeper在kafka中的作用"></a>zookeeper在kafka中的作用</h3><ol><li><strong>controller选举</strong>，所有的broker在zk &#x2F;controller下注册临时节点，任意一个抢先的broker注册成功，则为controller</li><li><strong>kafka consumer负载均衡</strong></li><li><strong>集群节点存活状态监测</strong></li><li><strong>topic创建触发</strong></li><li><strong>broker上线、下线的通知</strong></li><li><strong>ISR配置变更</strong></li></ol>]]></content>
    
    
    
    <tags>
      
      <tag>中间件</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>开放平台生态圈</title>
    <link href="/2023/05/07/%E7%AC%AC%E4%B8%80%E7%AF%87%E6%96%87%E7%AB%A0/"/>
    <url>/2023/05/07/%E7%AC%AC%E4%B8%80%E7%AF%87%E6%96%87%E7%AB%A0/</url>
    
    <content type="html"><![CDATA[<p>ISV身份：</p><p>应用：</p><h3 id="授权："><a href="#授权：" class="headerlink" title="授权："></a>授权：</h3><p>​    在淘宝开放平台上，授权是一种控制访问权限的机制。当开发者希望访问淘宝平台的用户数据或使用某些功能时，他们需要先向淘宝开放平台申请授权。用户可以根据自己的需求选择授权给特定的应用程序或服务，以便控制对自己个人信息的访问和使用。</p><p>​    授权通常涉及用户的身份验证和权限管理。开发者需要通过OAuth等认证协议来验证用户的身份，并获得用户的授权许可。用户可以选择授予应用程序特定的权限，例如读取商品信息、下单、发表评价等。用户在授权过程中可以查看应用程序请求的权限范围，并可以随时取消或更改授权。</p><p>API</p><p>消息</p><p>SPI</p><p>SDK</p><p>错误码</p>]]></content>
    
    
    
  </entry>
  
  
  
  
</search>
